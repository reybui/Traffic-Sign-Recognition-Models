{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b51f9d5",
   "metadata": {},
   "source": [
    "# Image Classification with SVM and MLP\n",
    "This notebook loads images from `archive/myData`, preprocesses them into fixed-size vectors, then trains and evaluates an SVM and MLP classifier. We first search hyperparameters on small subsets for speed, refine on a medium subset, and finally train on the full training split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7102e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data and ML stack\n",
    "import pandas as pd                     # tabular data structures (DataFrame)\n",
    "from sklearn import svm                 # Support Vector Machine classifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split  # hyperparam search + split\n",
    "import os                               # filesystem utilities\n",
    "import matplotlib.pyplot as plt          # plotting\n",
    "from skimage.transform import resize     # image resizing\n",
    "from skimage.io import imread           # image reading\n",
    "import numpy as np                      # numerical arrays\n",
    "\n",
    "# Metrics and models\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    mean_absolute_error,\n",
    "    precision_score,\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier  # sklearn MLP baseline\n",
    "\n",
    "# Persistence and DL backend\n",
    "import pickle                         # save/load preprocessed data and sklearn models\n",
    "import tensorflow as tf               # deep learning backend (used by Keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541e256",
   "metadata": {},
   "source": [
    "## Load and preprocess images\n",
    "- Discover class folders under `archive/myData`\n",
    "- Read each image, convert to RGB, resize to 32×32, scale to [0,1]\n",
    "- Flatten to feature vectors and build label arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d6c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading category: 0\n",
      "Loaded 0 successfully\n",
      "Loading category: 1\n",
      "Loaded 0 successfully\n",
      "Loading category: 1\n",
      "Loaded 1 successfully\n",
      "Loading category: 10\n",
      "Loaded 1 successfully\n",
      "Loading category: 10\n",
      "Loaded 10 successfully\n",
      "Loading category: 11\n",
      "Loaded 10 successfully\n",
      "Loading category: 11\n",
      "Loaded 11 successfully\n",
      "Loading category: 12\n",
      "Loaded 11 successfully\n",
      "Loading category: 12\n",
      "Loaded 12 successfully\n",
      "Loading category: 13\n",
      "Loaded 12 successfully\n",
      "Loading category: 13\n",
      "Loaded 13 successfully\n",
      "Loading category: 14\n",
      "Loaded 13 successfully\n",
      "Loading category: 14\n",
      "Loaded 14 successfully\n",
      "Loading category: 15\n",
      "Loaded 14 successfully\n",
      "Loading category: 15\n",
      "Loaded 15 successfully\n",
      "Loading category: 16\n",
      "Loaded 15 successfully\n",
      "Loading category: 16\n",
      "Loaded 16 successfully\n",
      "Loading category: 17\n",
      "Loaded 16 successfully\n",
      "Loading category: 17\n",
      "Loaded 17 successfully\n",
      "Loading category: 18\n",
      "Loaded 17 successfully\n",
      "Loading category: 18\n",
      "Loaded 18 successfully\n",
      "Loading category: 19\n",
      "Loaded 18 successfully\n",
      "Loading category: 19\n",
      "Loaded 19 successfully\n",
      "Loading category: 2\n",
      "Loaded 19 successfully\n",
      "Loading category: 2\n",
      "Loaded 2 successfully\n",
      "Loading category: 20\n",
      "Loaded 2 successfully\n",
      "Loading category: 20\n",
      "Loaded 20 successfully\n",
      "Loading category: 21\n",
      "Loaded 20 successfully\n",
      "Loading category: 21\n",
      "Loaded 21 successfully\n",
      "Loading category: 22\n",
      "Loaded 21 successfully\n",
      "Loading category: 22\n",
      "Loaded 22 successfully\n",
      "Loading category: 23\n",
      "Loaded 22 successfully\n",
      "Loading category: 23\n",
      "Loaded 23 successfully\n",
      "Loading category: 24\n",
      "Loaded 23 successfully\n",
      "Loading category: 24\n",
      "Loaded 24 successfully\n",
      "Loading category: 25\n",
      "Loaded 24 successfully\n",
      "Loading category: 25\n",
      "Loaded 25 successfully\n",
      "Loading category: 26\n",
      "Loaded 25 successfully\n",
      "Loading category: 26\n",
      "Loaded 26 successfully\n",
      "Loading category: 27\n",
      "Loaded 26 successfully\n",
      "Loading category: 27\n",
      "Loaded 27 successfully\n",
      "Loading category: 28\n",
      "Loaded 27 successfully\n",
      "Loading category: 28\n",
      "Loaded 28 successfully\n",
      "Loading category: 29\n",
      "Loaded 28 successfully\n",
      "Loading category: 29\n",
      "Loaded 29 successfully\n",
      "Loading category: 3\n",
      "Loaded 29 successfully\n",
      "Loading category: 3\n",
      "Loaded 3 successfully\n",
      "Loading category: 30\n",
      "Loaded 3 successfully\n",
      "Loading category: 30\n",
      "Loaded 30 successfully\n",
      "Loading category: 31\n",
      "Loaded 30 successfully\n",
      "Loading category: 31\n",
      "Loaded 31 successfully\n",
      "Loading category: 32\n",
      "Loaded 31 successfully\n",
      "Loading category: 32\n",
      "Loaded 32 successfully\n",
      "Loading category: 33\n",
      "Loaded 32 successfully\n",
      "Loading category: 33\n",
      "Loaded 33 successfully\n",
      "Loading category: 34\n",
      "Loaded 33 successfully\n",
      "Loading category: 34\n",
      "Loaded 34 successfully\n",
      "Loading category: 35\n",
      "Loaded 34 successfully\n",
      "Loading category: 35\n",
      "Loaded 35 successfully\n",
      "Loading category: 36\n",
      "Loaded 35 successfully\n",
      "Loading category: 36\n",
      "Loaded 36 successfully\n",
      "Loading category: 37\n",
      "Loaded 36 successfully\n",
      "Loading category: 37\n",
      "Loaded 37 successfully\n",
      "Loading category: 38\n",
      "Loaded 37 successfully\n",
      "Loading category: 38\n",
      "Loaded 38 successfully\n",
      "Loading category: 39\n",
      "Loaded 38 successfully\n",
      "Loading category: 39\n",
      "Loaded 39 successfully\n",
      "Loading category: 4\n",
      "Loaded 39 successfully\n",
      "Loading category: 4\n",
      "Loaded 4 successfully\n",
      "Loading category: 40\n",
      "Loaded 4 successfully\n",
      "Loading category: 40\n",
      "Loaded 40 successfully\n",
      "Loading category: 41\n",
      "Loaded 40 successfully\n",
      "Loading category: 41\n",
      "Loaded 41 successfully\n",
      "Loading category: 42\n",
      "Loaded 41 successfully\n",
      "Loading category: 42\n",
      "Loaded 42 successfully\n",
      "Loading category: 5\n",
      "Loaded 42 successfully\n",
      "Loading category: 5\n",
      "Loaded 5 successfully\n",
      "Loading category: 6\n",
      "Loaded 5 successfully\n",
      "Loading category: 6\n",
      "Loaded 6 successfully\n",
      "Loading category: 7\n",
      "Loaded 6 successfully\n",
      "Loading category: 7\n",
      "Loaded 7 successfully\n",
      "Loading category: 8\n",
      "Loaded 7 successfully\n",
      "Loading category: 8\n",
      "Loaded 8 successfully\n",
      "Loading category: 9\n",
      "Loaded 8 successfully\n",
      "Loading category: 9\n",
      "Loaded 9 successfully\n",
      "Loaded 9 successfully\n",
      "Prepared dataset with 73139 samples, feature length 3072, across 43 classes.\n",
      "Prepared dataset with 73139 samples, feature length 3072, across 43 classes.\n"
     ]
    }
   ],
   "source": [
    "# Point to the dataset root folder (archive/myData) relative to this notebook/workspace\n",
    "# Each subfolder under this directory represents one class label\n",
    "datadir = os.path.join('.', 'archive', 'myData')\n",
    "\n",
    "# Auto-discover category folders (e.g., '0', '1', ...). Keep only directories.\n",
    "# This builds the set of class names programmatically so no hard-coded list is needed.\n",
    "categories = [d for d in os.listdir(datadir) if os.path.isdir(os.path.join(datadir, d))]\n",
    "\n",
    "# Containers for features (flattened image vectors) and integer labels\n",
    "flat_data_arr = []\n",
    "target_arr = []\n",
    "\n",
    "# Define the target size (H, W, C) and ensure we always produce 3-channel RGB images\n",
    "# We standardize spatial dimensions so classical models (SVM/MLP) can accept fixed-length vectors.\n",
    "target_size = (32, 32, 3)\n",
    "\n",
    "# Read images, normalize channels, resize, and collect\n",
    "for category in categories:\n",
    "    print(f'Loading category: {category}')\n",
    "    path = os.path.join(datadir, category)\n",
    "    for img_name in os.listdir(path):\n",
    "        img_path = os.path.join(path, img_name)\n",
    "        # Skip non-files and non-image extensions\n",
    "        if not os.path.isfile(img_path):\n",
    "            continue\n",
    "        try:\n",
    "            img_array = imread(img_path)  # shape could be (H, W), (H, W, 3) or (H, W, 4)\n",
    "\n",
    "            # Ensure 3 channels (RGB)\n",
    "            if img_array.ndim == 2:  # grayscale -> RGB by stacking into 3 channels\n",
    "                img_array = np.stack([img_array] * 3, axis=-1)\n",
    "            elif img_array.ndim == 3 and img_array.shape[2] == 4:  # RGBA -> RGB (drop alpha)\n",
    "                img_array = img_array[:, :, :3]\n",
    "            elif img_array.ndim == 3 and img_array.shape[2] == 3:\n",
    "                pass  # already RGB\n",
    "            else:\n",
    "                # Unexpected shape: skip and report\n",
    "                print(f\"Warning: Skipping image {img_name} (unexpected shape: {img_array.shape})\")\n",
    "                continue\n",
    "\n",
    "            # Resize all images to target_size; skimage returns floats in [0,1] by default here\n",
    "            img_resized = resize(img_array, target_size, anti_aliasing=True)\n",
    "\n",
    "            # Only collect if the resized shape is as expected (defensive check)\n",
    "            if img_resized.shape == target_size:\n",
    "                flat_data_arr.append(img_resized.flatten())  # 32*32*3 = 3072 features\n",
    "                target_arr.append(categories.index(category))  # integer label index\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Skipping image {img_name} in category {category} due to unexpected shape after resizing: {img_resized.shape}\"\n",
    "                )\n",
    "\n",
    "        except Exception as e:\n",
    "            # Keep the pipeline robust: log and continue\n",
    "            print(f\"Error loading or processing image {img_name} in category {category}: {e}\")\n",
    "            continue\n",
    "    print(f'Loaded {category} successfully')\n",
    "\n",
    "# Convert to numpy arrays with explicit dtypes for downstream libraries\n",
    "default_feat_len = flat_data_arr[0].size if flat_data_arr else 0\n",
    "flat_data = np.array(flat_data_arr, dtype=np.float32)\n",
    "target = np.array(target_arr, dtype=np.int32)\n",
    "\n",
    "# Helpful label maps for human-readable reports and inverse transforms\n",
    "label_to_index = {cat: i for i, cat in enumerate(categories)}\n",
    "index_to_label = {i: cat for cat, i in label_to_index.items()}\n",
    "\n",
    "print(\n",
    "    f\"Prepared dataset with {flat_data.shape[0]} samples, feature length {flat_data.shape[1] if flat_data.size else 0}, across {len(categories)} classes.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead9ab56",
   "metadata": {},
   "source": [
    "## Cache preprocessed data (optional)\n",
    "We save `(flat_data, target)` into `data.pickle` so we can skip preprocessing next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c30a083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data pickled successfully.\n"
     ]
    }
   ],
   "source": [
    "# Persist preprocessed arrays to speed up future runs\n",
    "# This avoids re-reading and resizing thousands of images every time.\n",
    "with open('data.pickle', 'wb') as f:  # wb = write-binary\n",
    "    pickle.dump((flat_data, target), f)  # tuple: (features, labels)\n",
    "print(\"Data pickled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40ed63e",
   "metadata": {},
   "source": [
    "## Build DataFrame for modeling\n",
    "We create a DataFrame for convenience and append the numeric `Target` label column, which GridSearch and train/test split will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4d775d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>3063</th>\n",
       "      <th>3064</th>\n",
       "      <th>3065</th>\n",
       "      <th>3066</th>\n",
       "      <th>3067</th>\n",
       "      <th>3068</th>\n",
       "      <th>3069</th>\n",
       "      <th>3070</th>\n",
       "      <th>3071</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.349020</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427451</td>\n",
       "      <td>0.364706</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.290196</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.274510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.423529</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.219608</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.247059</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.380392</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.203922</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.525490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.341176</td>\n",
       "      <td>0.356863</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.403922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.215686  0.200000  0.254902  0.400000  0.349020  0.388235  0.435294   \n",
       "1  0.305882  0.290196  0.254902  0.286275  0.270588  0.227451  0.270588   \n",
       "2  0.243137  0.325490  0.329412  0.200000  0.278431  0.270588  0.317647   \n",
       "3  0.333333  0.270588  0.282353  0.301961  0.243137  0.254902  0.301961   \n",
       "4  0.247059  0.345098  0.262745  0.380392  0.372549  0.321569  0.376471   \n",
       "\n",
       "          7         8         9  ...      3063      3064      3065      3066  \\\n",
       "0  0.321569  0.341176  0.435294  ...  0.427451  0.364706  0.376471  0.447059   \n",
       "1  0.254902  0.211765  0.274510  ...  0.227451  0.215686  0.196078  0.231373   \n",
       "2  0.360784  0.329412  0.309804  ...  0.325490  0.305882  0.321569  0.400000   \n",
       "3  0.262745  0.258824  0.333333  ...  0.239216  0.223529  0.227451  0.235294   \n",
       "4  0.203922  0.200000  0.525490  ...  0.250980  0.282353  0.294118  0.298039   \n",
       "\n",
       "       3067      3068      3069      3070      3071  Target  \n",
       "0  0.372549  0.380392  0.447059  0.372549  0.380392       0  \n",
       "1  0.211765  0.188235  0.235294  0.215686  0.192157       0  \n",
       "2  0.384314  0.388235  0.423529  0.400000  0.407843       0  \n",
       "3  0.219608  0.223529  0.231373  0.215686  0.219608       0  \n",
       "4  0.329412  0.341176  0.356863  0.396078  0.403922       0  \n",
       "\n",
       "[5 rows x 3073 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload features/labels from cache for modeling (avoids repeating preprocessing)\n",
    "flat_data, target = pickle.load(open('data.pickle', 'rb'))  # rb = read-binary\n",
    "\n",
    "# Build a DataFrame where each row is an image's flattened features\n",
    "# Append the numeric label column `Target` for convenience with sklearn APIs\n",
    "df = pd.DataFrame(flat_data)\n",
    "df['Target'] = target\n",
    "\n",
    "# Peek at the first few rows to confirm shapes and label presence\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f46c5",
   "metadata": {},
   "source": [
    "## Train/test split\n",
    "Split features/labels into training and test sets with stratification to preserve class proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f0467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-test split done.\n"
     ]
    }
   ],
   "source": [
    "# Split features/labels into train and test sets\n",
    "# - test_size=0.3 keeps 30% for final evaluation\n",
    "# - stratify=y preserves class distribution across splits\n",
    "# - random_state ensures reproducibility across runs\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=33, stratify=y\n",
    ")\n",
    "print(\"Train-test split done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bcf66a",
   "metadata": {},
   "source": [
    "## Quick subset for fast tuning\n",
    "We build a small stratified subset (e.g., 20 per class) to do a fast initial GridSearch and get a good hyperparameter ballpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baef20f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset created: 860 samples across 43 classes\n"
     ]
    }
   ],
   "source": [
    "# Create a small, stratified subset for quick GridSearch experiments\n",
    "# Strategy: cap the number of samples per class to bound runtime while keeping class balance.\n",
    "from collections import defaultdict\n",
    "\n",
    "def make_stratified_subset(X, y, max_per_class, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)  # deterministic shuffling\n",
    "    counts = defaultdict(int)                  # track how many picked per class\n",
    "    idxs = []\n",
    "    y_np = np.asarray(y)\n",
    "\n",
    "    # Shuffle indices for randomness\n",
    "    all_idxs = np.arange(len(y_np))\n",
    "    rng.shuffle(all_idxs)\n",
    "\n",
    "    # Greedy selection up to max_per_class for each class label\n",
    "    for i in all_idxs:\n",
    "        label = y_np[i]\n",
    "        if counts[label] < max_per_class:\n",
    "            idxs.append(i)\n",
    "            counts[label] += 1\n",
    "\n",
    "    # Return new X/y with contiguous indices for convenience\n",
    "    return X.iloc[idxs].reset_index(drop=True), y.iloc[idxs].reset_index(drop=True)\n",
    "\n",
    "# Build a reduced training set (e.g., 20 examples per class)\n",
    "X_train_small, y_train_small = make_stratified_subset(X_train, y_train, max_per_class=20)\n",
    "print(f\"Subset created: {len(y_train_small)} samples across {y_train_small.nunique()} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70722ace",
   "metadata": {},
   "source": [
    "## Medium subset for refinement\n",
    "We validate and refine around the initial best parameters using a larger subset (e.g., 100 per class) to reduce noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae3905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium subset created: 4300 samples across 43 classes\n"
     ]
    }
   ],
   "source": [
    "# Create a larger (medium) stratified subset to validate/refine hyperparameters\n",
    "# Using ~100 per class reduces CV noise and yields more reliable best params than the tiny subset\n",
    "X_train_med, y_train_med = make_stratified_subset(X_train, y_train, max_per_class=100)\n",
    "print(f\"Medium subset created: {len(y_train_med)} samples across {y_train_med.nunique()} classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f40be",
   "metadata": {},
   "source": [
    "## Coarse GridSearch on subset\n",
    "Coarse sweep across C and gamma to identify a promising region quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d373f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick GridSearch on a reduced subset; for final training, run on full X_train, y_train\n",
      "The Model is trained on the subset with the given images\n",
      "The Model is trained on the subset with the given images\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coarse parameter sweep on a small subset to find a promising region quickly\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],              # regularization strength (higher = tighter fit)\n",
    "    'gamma': [1e-4, 1e-3, 1e-1],    # RBF kernel width (higher = more complex boundary)\n",
    "    'kernel': ['rbf', 'poly'],      # try RBF and polynomial briefly\n",
    "}\n",
    "svc = svm.SVC(probability=True)      # enable probabilities if needed later (adds overhead)\n",
    "print(\"Quick GridSearch on a reduced subset; for final training, run on full X_train, y_train\")\n",
    "model = GridSearchCV(svc, param_grid)  \n",
    "model.fit(X_train_small, y_train_small)\n",
    "print('The Model is trained on the subset with the given images')\n",
    "model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40122443",
   "metadata": {},
   "source": [
    "## Refined GridSearch on medium subset\n",
    "Narrow search around the best (C, gamma) from the coarse step using more samples for stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9b738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined GridSearch on medium subset...\n",
      "Refined best params: {'C': 80, 'gamma': 0.003, 'kernel': 'rbf'}\n",
      "Refined best params: {'C': 80, 'gamma': 0.003, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 80, 'gamma': 0.003, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refine around the current best on the medium subset\n",
    "# Narrow the search near the coarse best to get a more stable estimate before full training\n",
    "refined_param_grid = {\n",
    "    'C': [1, 10, 20, 50, 60, 80],  # explore around previously good C\n",
    "    'gamma': [0.001, 0.003, 0.005], # sweep around previously good gamma\n",
    "    'kernel': ['rbf', 'poly']       # keep both kernels for robustness\n",
    "}\n",
    "svc = svm.SVC(probability=True)\n",
    "refined_model = GridSearchCV(svc, refined_param_grid)\n",
    "print(\"Refined GridSearch on medium subset...\")\n",
    "refined_model.fit(X_train_med, y_train_med)\n",
    "print(\"Refined best params:\", refined_model.best_params_)\n",
    "refined_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bc967",
   "metadata": {},
   "source": [
    "## Final training and evaluation\n",
    "Train the chosen SVM on the full training set, save the model, then evaluate accuracy on the held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e69dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.sav\n",
      "Accuracy (model.score): 0.9878315559201531\n",
      "Accuracy (model.score): 0.9878315559201531\n"
     ]
    }
   ],
   "source": [
    "# Train the chosen SVM on the full training set, then persist and evaluate on the held-out test set\n",
    "svm_model = svm.SVC(C=30, kernel='rbf', gamma=0.003)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained SVM model for reuse\n",
    "with open('model.sav', 'wb') as f:\n",
    "    pickle.dump(svm_model, f)\n",
    "print(\"Model saved as model.sav\")\n",
    "\n",
    "# Reload (to simulate separate evaluation step), predict, and compute accuracy\n",
    "with open('model.sav', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "acc = loaded_model.score(X_test, y_test)  # equivalent to accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy (model.score):\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed4bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[ 135    0    0 ...    0    0    0]\n",
      " [   0 1466    0 ...    0    4    0]\n",
      " [   0    2 1131 ...    0    0    0]\n",
      " ...\n",
      " [   0    1    1 ...  778    6    1]\n",
      " [   0    0    1 ...    0  792    0]\n",
      " [   0    0    6 ...    0    0  826]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       135\n",
      "           1       0.99      0.99      0.99      1476\n",
      "          10       0.98      0.99      0.99      1143\n",
      "          11       0.99      0.99      0.99       747\n",
      "          12       0.99      0.99      0.99      1197\n",
      "          13       1.00      1.00      1.00      1224\n",
      "          14       1.00      1.00      1.00       441\n",
      "          15       0.99      0.99      0.99       351\n",
      "          16       0.99      1.00      1.00       234\n",
      "          17       1.00      1.00      1.00       630\n",
      "          18       0.98      0.99      0.98       684\n",
      "          19       0.99      0.96      0.97       117\n",
      "           2       0.97      0.97      0.97       783\n",
      "          20       0.97      0.98      0.97       198\n",
      "          21       0.99      0.98      0.99       180\n",
      "          22       1.00      1.00      1.00       216\n",
      "          23       1.00      1.00      1.00       288\n",
      "          24       0.97      0.99      0.98       153\n",
      "          25       0.99      1.00      0.99       855\n",
      "          26       1.00      0.96      0.98       342\n",
      "          27       0.99      1.00      0.99       135\n",
      "          28       0.99      1.00      1.00       306\n",
      "          29       1.00      0.99      0.99       153\n",
      "           3       0.96      0.96      0.96       801\n",
      "          30       1.00      0.98      0.99       252\n",
      "          31       1.00      1.00      1.00       441\n",
      "          32       1.00      0.98      0.99       135\n",
      "          33       1.00      0.99      0.99       387\n",
      "          34       1.00      1.00      1.00       234\n",
      "          35       1.00      0.99      1.00       684\n",
      "          36       0.99      1.00      1.00       216\n",
      "          37       1.00      1.00      1.00       117\n",
      "          38       1.00      1.00      1.00      1179\n",
      "          39       0.99      1.00      1.00       171\n",
      "           4       0.97      0.99      0.98      1125\n",
      "          40       0.99      0.99      0.99       198\n",
      "          41       0.99      0.97      0.98       135\n",
      "          42       0.99      1.00      1.00       135\n",
      "           5       0.97      0.98      0.97      1053\n",
      "           6       0.99      1.00      0.99       234\n",
      "           7       1.00      0.95      0.97       819\n",
      "           8       0.99      0.99      0.99       801\n",
      "           9       0.99      0.99      0.99       837\n",
      "\n",
      "    accuracy                           0.99     21942\n",
      "   macro avg       0.99      0.99      0.99     21942\n",
      "weighted avg       0.99      0.99      0.99     21942\n",
      "\n",
      "\n",
      "Overall Accuracy: 98.78%\n"
     ]
    }
   ],
   "source": [
    "# Compute and display confusion matrix and a detailed classification report\n",
    "# - Confusion matrix: counts of predicted vs true labels per class\n",
    "# - Classification report: precision, recall, and F1 per class and their averages\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[index_to_label[i] for i in range(len(categories))]))\n",
    "\n",
    "print(f\"\\nOverall Accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816153d",
   "metadata": {},
   "source": [
    "## Keras MLP: architecture, training, and evaluation\n",
    "\n",
    "- What: A simple feed-forward neural network implemented in TensorFlow/Keras.\n",
    "- Inputs: Flattened pixel vectors of shape `[num_samples, num_features]`.\n",
    "- Preprocessing: We use a `Normalization` layer that learns statistics from the training data and applies them to both train and test.\n",
    "- Architecture:\n",
    "  - Dense(512, ReLU) → Dropout(0.3)\n",
    "  - Dense(256, ReLU) → Dropout(0.3)\n",
    "  - Dense(`num_classes`, Softmax)\n",
    "- Training:\n",
    "  - Loss: `SparseCategoricalCrossentropy` (labels are integer-encoded)\n",
    "  - Optimizer: Adam with lr=1e-3\n",
    "  - Callbacks: `EarlyStopping(patience=5)` and `ReduceLROnPlateau(patience=3)`\n",
    "- Monitoring:\n",
    "  - `accuracy` is training accuracy\n",
    "  - `val_accuracy` is validation accuracy using 20% of the training data\n",
    "- After training: We evaluate on the held-out test set and save the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7619be83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.4102 - loss: 2.2441 - val_accuracy: 0.6869 - val_loss: 1.0864 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6627 - loss: 1.1368 - val_accuracy: 0.7862 - val_loss: 0.7347 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7378 - loss: 0.8821 - val_accuracy: 0.8315 - val_loss: 0.5610 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7743 - loss: 0.7569 - val_accuracy: 0.8539 - val_loss: 0.5040 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.7926 - loss: 0.6982 - val_accuracy: 0.8623 - val_loss: 0.5208 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.8055 - loss: 0.6627 - val_accuracy: 0.8808 - val_loss: 0.4102 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.8135 - loss: 0.6317 - val_accuracy: 0.8733 - val_loss: 0.4453 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8203 - loss: 0.6000 - val_accuracy: 0.8872 - val_loss: 0.3924 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8382 - loss: 0.5534 - val_accuracy: 0.8615 - val_loss: 0.4481 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8344 - loss: 0.5769 - val_accuracy: 0.8975 - val_loss: 0.3715 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8401 - loss: 0.5431 - val_accuracy: 0.9099 - val_loss: 0.3390 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8420 - loss: 0.5449 - val_accuracy: 0.9098 - val_loss: 0.3198 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8513 - loss: 0.5178 - val_accuracy: 0.9137 - val_loss: 0.3253 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.8557 - loss: 0.5165 - val_accuracy: 0.8883 - val_loss: 0.3659 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m637/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8619 - loss: 0.4940\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8557 - loss: 0.5169 - val_accuracy: 0.9139 - val_loss: 0.3253 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9127 - loss: 0.2970 - val_accuracy: 0.9430 - val_loss: 0.2134 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9198 - loss: 0.2668 - val_accuracy: 0.9545 - val_loss: 0.1826 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9242 - loss: 0.2512 - val_accuracy: 0.9485 - val_loss: 0.1994 - learning_rate: 5.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9233 - loss: 0.2550 - val_accuracy: 0.9590 - val_loss: 0.1867 - learning_rate: 5.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m636/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9225 - loss: 0.2518\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9230 - loss: 0.2510 - val_accuracy: 0.9485 - val_loss: 0.1981 - learning_rate: 5.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9506 - loss: 0.1667 - val_accuracy: 0.9738 - val_loss: 0.1228 - learning_rate: 2.5000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9549 - loss: 0.1485 - val_accuracy: 0.9722 - val_loss: 0.1282 - learning_rate: 2.5000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9540 - loss: 0.1452 - val_accuracy: 0.9724 - val_loss: 0.1260 - learning_rate: 2.5000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m635/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9586 - loss: 0.1402\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9570 - loss: 0.1430 - val_accuracy: 0.9737 - val_loss: 0.1241 - learning_rate: 2.5000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9663 - loss: 0.1107 - val_accuracy: 0.9784 - val_loss: 0.0986 - learning_rate: 1.2500e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.9682 - loss: 0.1003 - val_accuracy: 0.9809 - val_loss: 0.0965 - learning_rate: 1.2500e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9708 - loss: 0.0953 - val_accuracy: 0.9834 - val_loss: 0.0921 - learning_rate: 1.2500e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9700 - loss: 0.0934 - val_accuracy: 0.9811 - val_loss: 0.0939 - learning_rate: 1.2500e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9720 - loss: 0.0914 - val_accuracy: 0.9803 - val_loss: 0.0959 - learning_rate: 1.2500e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9715 - loss: 0.0903 - val_accuracy: 0.9832 - val_loss: 0.0893 - learning_rate: 1.2500e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9716 - loss: 0.0939 - val_accuracy: 0.9842 - val_loss: 0.0890 - learning_rate: 1.2500e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9727 - loss: 0.0883 - val_accuracy: 0.9823 - val_loss: 0.0945 - learning_rate: 1.2500e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9725 - loss: 0.0901 - val_accuracy: 0.9792 - val_loss: 0.0971 - learning_rate: 1.2500e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.9732 - loss: 0.0880 - val_accuracy: 0.9823 - val_loss: 0.0887 - learning_rate: 1.2500e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9737 - loss: 0.0846 - val_accuracy: 0.9827 - val_loss: 0.0887 - learning_rate: 1.2500e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9742 - loss: 0.0822 - val_accuracy: 0.9855 - val_loss: 0.0807 - learning_rate: 1.2500e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.9759 - loss: 0.0777 - val_accuracy: 0.9854 - val_loss: 0.0852 - learning_rate: 1.2500e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.9759 - loss: 0.0745 - val_accuracy: 0.9864 - val_loss: 0.0789 - learning_rate: 1.2500e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9756 - loss: 0.0782 - val_accuracy: 0.9846 - val_loss: 0.0879 - learning_rate: 1.2500e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9768 - loss: 0.0762 - val_accuracy: 0.9843 - val_loss: 0.0918 - learning_rate: 1.2500e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9769 - loss: 0.0761\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9768 - loss: 0.0751 - val_accuracy: 0.9819 - val_loss: 0.0874 - learning_rate: 1.2500e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9803 - loss: 0.0635 - val_accuracy: 0.9882 - val_loss: 0.0751 - learning_rate: 6.2500e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0567 - val_accuracy: 0.9870 - val_loss: 0.0769 - learning_rate: 6.2500e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0570 - val_accuracy: 0.9882 - val_loss: 0.0738 - learning_rate: 6.2500e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0582 - val_accuracy: 0.9884 - val_loss: 0.0753 - learning_rate: 6.2500e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9816 - loss: 0.0582 - val_accuracy: 0.9884 - val_loss: 0.0733 - learning_rate: 6.2500e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9823 - loss: 0.0556 - val_accuracy: 0.9891 - val_loss: 0.0731 - learning_rate: 6.2500e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9829 - loss: 0.0559 - val_accuracy: 0.9881 - val_loss: 0.0745 - learning_rate: 6.2500e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9828 - loss: 0.0568 - val_accuracy: 0.9885 - val_loss: 0.0721 - learning_rate: 6.2500e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m640/640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9828 - loss: 0.0561 - val_accuracy: 0.9896 - val_loss: 0.0718 - learning_rate: 6.2500e-05\n",
      "Test accuracy: 0.9880\n",
      "Model saved as MLPmodel.sav\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras  # Keras high-level API on top of TensorFlow\n",
    "\n",
    "num_classes = 43  # number of unique categories detected earlier\n",
    "\n",
    "# Ensure NumPy arrays for Keras (and explicit dtypes)\n",
    "X_train_np = X_train.values.astype(\"float32\")\n",
    "X_test_np  = X_test.values.astype(\"float32\")\n",
    "y_train_np = y_train.values.astype(\"int64\")   # SparseCategoricalCrossentropy expects int labels\n",
    "y_test_np  = y_test.values.astype(\"int64\")\n",
    "\n",
    "# Feature normalization (fit on train only to avoid leakage)\n",
    "norm = keras.layers.Normalization()  # learns mean/variance from the training data\n",
    "norm.adapt(X_train_np)\n",
    "\n",
    "# Define a simple feed-forward MLP architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_np.shape[1],)),  # feature dimension (e.g., 3072 for 32x32x3)\n",
    "    norm,                                             # apply normalization learned from X_train\n",
    "    keras.layers.Dense(512, activation='relu'),       # first hidden layer\n",
    "    keras.layers.Dropout(0.3),                        # dropout to reduce overfitting\n",
    "    keras.layers.Dense(256, activation='relu'),       # second hidden layer\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(num_classes, activation='softmax'),  # output over classes\n",
    "])\n",
    "\n",
    "# Compile with an optimizer, loss, and metrics\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),  # integer class labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Training callbacks for better generalization and automatic LR tuning\n",
    "es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)     # stop when val doesn't improve\n",
    "rlrop = keras.callbacks.ReduceLROnPlateau(patience=3, factor=0.5, verbose=1)  # lower LR on plateaus\n",
    "\n",
    "# Fit the model with an internal validation split (taken from training data)\n",
    "history = model.fit(\n",
    "    X_train_np, y_train_np,\n",
    "    epochs=50, batch_size=64, validation_split=0.2,\n",
    "    callbacks=[es, rlrop], verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate on the held-out test set (never seen during training/validation)\n",
    "test_loss, test_acc = model.evaluate(X_test_np, y_test_np, verbose=0)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Saving model in pickle\n",
    "pickle.dump(model, open('MLPmodel.sav', 'wb'))\n",
    "print(\"Model saved as MLPmodel.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af57f8",
   "metadata": {},
   "source": [
    "## Plot training vs validation accuracy\n",
    "\n",
    "- Purpose: Visualize convergence and overfitting before we look at test metrics.\n",
    "- Read the curves:\n",
    "  - If training accuracy climbs while validation plateaus or drops, the model may be overfitting.\n",
    "  - If both improve slowly, consider tuning learning rate, batch size, or architecture.\n",
    "- Goal: Aim for a small gap between training and validation accuracy with both trending upward and stabilizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa60909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAHUCAYAAAAp/qBkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/HUlEQVR4nO3dd3xT9f7H8VeStumgLS2jlFWm7KGACAqCDAUcXEXBAbJULoLyw+vkOlCveB3IdeFiKSqIiperqFSZgiggILKUWUahlNXdpsn5/XHaQGmBjtA04f18PPJIcnLGN/m29M03n/M9FsMwDEREREREfJDV2w0QERERESkthVkRERER8VkKsyIiIiLisxRmRURERMRnKcyKiIiIiM9SmBURERERn6UwKyIiIiI+S2FWRERERHyWwqyIiIiI+CyFWRGpcGbOnInFYjnrbenSpV5t3549e7BYLLzyyitebUdxvP7661gsFlq2bOntpoiIXBAB3m6AiMjZzJgxg6ZNmxZa3rx5cy+0xjdNnz4dgM2bN/PLL7/QsWNHL7dIRMSzFGZFpMJq2bIl7du393YzfNbatWvZuHEj/fr145tvvmHatGkVNsxmZGQQGhrq7WaIiA9SmYGI+DSLxcKYMWN49913ueSSS7Db7TRv3pw5c+YUWvePP/7gpptuIioqiuDgYNq2bcusWbMKrXfixAkeeughGjRogN1up3r16vTt25dt27YVWnfy5MnUr1+fSpUq0alTJ1avXn3O9m7cuBGLxcK0adMKvfbtt99isVhYsGABAEeOHOHee++lTp062O12qlWrxpVXXskPP/xQrM8m/xgvvvginTt3Zs6cOWRkZBRa78CBA+7jBAUFUbNmTQYMGMDhw4eL/ZksXbq0yBKQ/JKMmTNnupcNHTqUSpUqsWnTJnr37k14eDg9evQAID4+nptuuonatWsTHBxMo0aNuO+++0hOTi7U7m3btnH77bcTExOD3W6nbt26DBkyhOzsbPbs2UNAQACTJk0qtN3y5cuxWCzMmzevWJ+jiFRsGpkVkQrL6XSSm5tbYJnFYsFmsxVYtmDBApYsWcKzzz5LWFgYb7/9NrfffjsBAQEMGDAAgO3bt9O5c2eqV6/O66+/TpUqVZg9ezZDhw7l8OHDPPLIIwCkpqZy1VVXsWfPHh599FE6duxIWloay5cvJzExsUDZw1tvvUXTpk2ZMmUKAE8++SR9+/Zl9+7dREZGFvme2rRpw6WXXsqMGTMYMWJEgddmzpzpDokAgwcP5rfffuNf//oXl1xyCSdOnOC3337j6NGj5/3sMjMz+fTTT+nQoQMtW7Zk+PDhjBw5knnz5nH33Xe71ztw4AAdOnTA4XDwxBNP0Lp1a44ePcr333/P8ePHiYmJKdFnUlw5OTnceOON3HfffTz22GPuft65cyedOnVi5MiRREZGsmfPHiZPnsxVV13Fpk2bCAwMBMz/FFx11VVUrVqVZ599lsaNG5OYmMiCBQvIycmhXr163Hjjjbzzzjs88sgjBX5m3nzzTWrWrMnf/va3ErdbRCogQ0SkgpkxY4YBFHmz2WwF1gWMkJAQ49ChQ+5lubm5RtOmTY1GjRq5lw0aNMiw2+1GQkJCge379OljhIaGGidOnDAMwzCeffZZAzDi4+PP2r7du3cbgNGqVSsjNzfXvfzXX381AOPTTz895/t7/fXXDcDYvn27e9mxY8cMu91uPPTQQ+5llSpVMsaNG3fOfZ3Nhx9+aADGO++8YxiGYaSmphqVKlUyunTpUmC94cOHG4GBgcaWLVvOuq/ifCZLliwxAGPJkiUFlud/VjNmzHAvu/vuuw3AmD59+jnfg8vlMhwOh7F3714DMP773/+6X7vmmmuMypUrG0lJSedt0/z5893LDhw4YAQEBBgTJ04857FFxHeozEBEKqwPP/yQNWvWFLj98ssvhdbr0aMHMTEx7uc2m42BAweyY8cO9u/fD8DixYvp0aMHderUKbDt0KFDycjI4OeffwbMr/ovueQSevbsed729evXr8CIX+vWrQHYu3fvObe78847sdvtBb56//TTT8nOzmbYsGHuZZdffjkzZ87k+eefZ/Xq1TgcjvO2Kd+0adMICQlh0KBBAFSqVIlbb72VFStW8Ndff7nX+/bbb+nevTvNmjU7675K8pmUxC233FJoWVJSEqNGjaJOnToEBAQQGBhIXFwcAFu3bgXM+tply5Zx2223Ua1atbPuv1u3brRp04a33nrLveydd97BYrFw7733evS9iIj3KMyKSIXVrFkz2rdvX+DWrl27QuvVqFHjrMvyv5I/evQosbGxhdarWbNmgfWOHDlC7dq1i9W+KlWqFHhut9sB8yv+c4mOjubGG2/kww8/xOl0AmaJweWXX06LFi3c682dO5e7776bDz74gE6dOhEdHc2QIUM4dOjQOfe/Y8cOli9fTr9+/TAMgxMnTnDixAl3yUX+DAfFfb8l+UyKKzQ0lIiIiALLXC4XvXv35ssvv+SRRx7hxx9/5Ndff3XXIed/rsePH8fpdBarTQ888AA//vgj27dvx+Fw8P777zNgwIAif2ZExDcpzIqIzysq3OUvyw+cVapUITExsdB6Bw8eBKBq1aoAVKtWzT2aeyENGzaMAwcOEB8fz5YtW1izZk2BUdn8Nk2ZMoU9e/awd+9eJk2axJdffsnQoUPPue/p06djGAaff/45UVFR7lu/fv0AmDVrljtEF+f9Fmed4OBgALKzswssL+rELTBrn8/0xx9/sHHjRl5++WXGjh1Lt27d6NChQ6H/NERHR2Oz2YrVT3fccQdVqlThrbfeYt68eRw6dIj777//vNuJiO9QmBURn/fjjz8WOPPe6XQyd+5cGjZs6B6969GjB4sXL3aH13wffvghoaGhXHHFFQD06dOHP//8k8WLF1/QNvfu3ZtatWoxY8YMZsyYQXBwMLfffvtZ169bty5jxoyhV69e/Pbbb2ddz+l0MmvWLBo2bMiSJUsK3R566CESExP59ttvAfP9LlmyhO3bt591n8X5TOrVqwfA77//XmB5/swMxZEfcPNHuPO9++67BZ6HhIRw9dVXM2/evLOG5XzBwcHce++9zJo1i8mTJ9O2bVuuvPLKYrdJRCo+zWYgIhXWH3/8UWg2A4CGDRsWqJWsWrUq11xzDU8++aR7NoNt27YVmJ7r6aef5uuvv6Z79+489dRTREdH8/HHH/PNN9/w0ksvuWcfGDduHHPnzuWmm27iscce4/LLLyczM5Nly5Zx/fXX0717d4+8N5vNxpAhQ5g8eTIRERHcfPPNBWZAOHnyJN27d+eOO+6gadOmhIeHs2bNGr777jtuvvnms+7322+/5eDBg/z73/+mW7duhV5v2bIlb775JtOmTeP666/n2Wef5dtvv6Vr16488cQTtGrVihMnTvDdd98xfvx4mjZtWqzPpEaNGvTs2ZNJkyYRFRVFXFwcP/74I19++WWxP5OmTZvSsGFDHnvsMQzDIDo6mv/973/Ex8cXWjd/hoOOHTvy2GOP0ahRIw4fPsyCBQt49913CQ8Pd687evRoXnrpJdatW8cHH3xQ7PaIiI/w8gloIiKFnGs2A8B4//333esCxv3332+8/fbbRsOGDY3AwECjadOmxscff1xov5s2bTJuuOEGIzIy0ggKCjLatGlT4Cz7fMePHzcefPBBo27dukZgYKBRvXp1o1+/fsa2bdsMwzh1hv7LL79caFvAePrpp4v1Pv/880/3ezpzpoCsrCxj1KhRRuvWrY2IiAgjJCTEaNKkifH0008b6enpZ91n//79jaCgoHOe5T9o0CAjICDAPQPEvn37jOHDhxs1atQwAgMDjZo1axq33Xabcfjw4WJ/JoZhGImJicaAAQOM6OhoIzIy0rjrrruMtWvXFjmbQVhYWJFt27Jli9GrVy8jPDzciIqKMm699VYjISGhyM91y5Ytxq233mpUqVLFCAoKMurWrWsMHTrUyMrKKrTfbt26GdHR0UZGRsZZPxcR8U0WwzAMb4RoERFPsFgs3H///bz55pvebopUUElJScTFxTF27FheeuklbzdHRDxMZQYiIuKX9u/fz65du3j55ZexWq08+OCD3m6SiFwAOgFMRET80gcffEC3bt3YvHkzH3/8MbVq1fJ2k0TkAlCZgYiIiIj4LI3MioiIiIjPUpgVEREREZ+lMCsiIiIiPuuim83A5XJx8OBBwsPDi7ycooiIiIh4l2EYpKamUrNmTazWc4+9XnRh9uDBg9SpU8fbzRARERGR89i3b5/7suRnc9GF2fxLHO7bt4+IiIhyOabD4WDRokX07t2bwMDAcjmmXBjqS/+hvvQf6kv/ob70H2Xty5SUFOrUqVPg0tRnc9GF2fzSgoiIiHINs6GhoUREROiX08epL/2H+tJ/qC/9h/rSf3iqL4tTEqoTwERERETEZynMioiIiIjPUpgVEREREZ910dXMFodhGOTm5uJ0Oj2yP4fDQUBAAFlZWR7bp3iHP/SlzWYjICBAU9OJiIhf8GqYXb58OS+//DLr1q0jMTGR+fPn079//3Nus2zZMsaPH8/mzZupWbMmjzzyCKNGjfJYm3JyckhMTCQjI8Nj+zQMgxo1arBv3z4FCB/nL30ZGhpKbGwsQUFB3m6KiIhImXg1zKanp9OmTRuGDRvGLbfcct71d+/eTd++fbnnnnuYPXs2K1euZPTo0VSrVq1Y25+Py+Vi9+7d2Gw2atasSVBQkEcCi8vlIi0tjUqVKp134l+p2Hy9Lw3DICcnhyNHjrB7924aN27sk+9DREQkn1fDbJ8+fejTp0+x13/nnXeoW7cuU6ZMAaBZs2asXbuWV155xSNhNicnB5fLRZ06dQgNDS3z/vK5XC5ycnIIDg5WcPBx/tCXISEhBAYGsnfvXvd7ERER8VU+VTP7888/07t37wLLrr32WqZNm4bD4ShyHrPs7Gyys7Pdz1NSUgCz9tHhcBRY1+FwYBgGYIYWT8nfp2EYHt2vlD9/6kvDMHA4HNhsNm83xSvyf//P/HdAfI/60n+oL/1HWfuyJNv5VJg9dOgQMTExBZbFxMSQm5tLcnIysbGxhbaZNGkSEydOLLR80aJFhUZfAwICqFGjBmlpaeTk5Hi28UBqaqrH9yne4et9mZOTQ2ZmJsuXLyc3N9fbzfGq+Ph4bzdBPER96T/Ul/6jtH1ZknOXfCrMQuErQeSPlJ2ttvXxxx9n/Pjx7uf5l0fr3bt3oSuAZWVlsW/fPipVquTRr14NwyA1NZXw8HCfPmlI/Kcvs7KyCAkJoWvXrhdtmYHD4SA+Pp5evXrpSkM+Tn3pP9SX/qOsfZn/TXpx+FSYrVGjBocOHSqwLCkpiYCAAKpUqVLkNna7HbvdXmh5YGBgoQ/X6XRisViwWq0erYfM/zo6f9++olu3brRt29Zdoyy+25dnslqtWCyWIn8PLjb6DPyH+tJ/qC/9R2n7siTb+NRf406dOhUarl60aBHt27e/qH/oLRbLOW9Dhw4t1X6//PJLnnvuOY+0cdWqVdhsNq677jqP7E9EREQEvBxm09LS2LBhAxs2bADMqbc2bNhAQkICYJYIDBkyxL3+qFGj2Lt3L+PHj2fr1q1Mnz6dadOm8Y9//MMbza8wEhMT3bcpU6YQERFRYNl//vOfAusXt6g6Ojqa8PBwj7Rx+vTpjB07lp9++sndv96iEwtERET8h1fD7Nq1a7n00ku59NJLARg/fjyXXnopTz31FGCGtNODT/369Vm4cCFLly6lbdu2PPfcc7z++usemZbrbAzDICMnt8y3zBxnibfJrwc+nxo1arhvkZGRWCwW9/OsrCwqV67MZ599Rrdu3QgODmb27NkcPXqU22+/ndq1axMaGkqrVq349NNPC+y3W7dujBs3zv28Xr16vPDCCwwfPpzw8HDq1q3Le++9d972paen89lnn/H3v/+d66+/npkzZxZaZ8GCBbRv357g4GCqVq3KzTff7H4tOzubRx55hDp16mC322ncuDHTpk0DYObMmVSuXLnAvr766qsC9azPPPMMbdu2Zfr06TRo0AC73Y5hGHz33XdcddVVVK5cmSpVqnD99dezc+fOAvvav38/gwYNIjo6mrCwMC6//HLWrl3Lnj17sFqtrF27tsD6b7zxBnFxccXuOxER8TGGAS4nOB3gyIKcdMhOLdkt8zikJMKxXXB4C+xfB3t+gr9+gK3/g9/nwW8fwi/vwsr/wOp3YP1s2PJf2PEj7PvV3O5EAmQcM9tyPi4X5GZDdpp5/LQkOHkAkraZ+/srHjZ9Dms+gBWvQvxT8L9xMG8YfHQzvN8D3mgPBzdc6E+4xLxaM9utW7dz/tEvKvRcffXV/PbbbxewVQVlOpw0f+r7cjve6bY8ey2hQZ7pokcffZRXX32VGTNmYLfbycrKol27djz66KNERETwzTffMHjwYBo0aEDHjh3Pup9XX32V5557jieeeILPP/+cv//973Tt2pWmTZuedZu5c+fSpEkTmjRpwl133cXYsWN58skn3YHzm2++4eabb2bChAl89NFH5OTk8M0337i3HzJkCD///DOvv/46bdq0Yffu3SQnJ5fo/e/YsYPPPvuML774wj0VVXp6OuPHj6dVq1akp6fz1FNP8be//Y0NGzZgtVpJS0vj6quvplatWixYsIAaNWqwdu1aXC4X9erVo2fPnsyYMYP27du7jzNjxgyGDh3q0yeHiYhUaCf3m4Fvy38h+S+wh0NwJARH5N1HQnBlsJ/+PMJ8npsNWScg6yRkp5j3WSch67TH+ctz0sFwmcHVcIHhNB9TQQcrbHawV4KAYDPcuhzgzM27zzHfgydklOzvb3nwqRPApPTGjRtXYLQTKFCeMXbsWL777jvmzZt3zjDbt29fRo8eDZgB+bXXXmPp0qXnDLPTpk3jrrvuAuC6664jLS2NH3/8kZ49ewLwr3/9i0GDBhWYQq1NmzYA/Pnnn3z22WfEx8e712/QoEFJ3jpgTkX10UcfUa1aNfeyM0f0p02bRvXq1dmyZQstW7bkk08+4ciRI6xZs4bo6Gj3sfPPsBw5ciSjRo1i8uTJ2O12Nm7cyIYNG/jyyy9L3D4RkSIZBqQmwtEd5kiaxQJYwGI1H1usec9Pf5z3pasjA3LSzJG4nPxRwbQzlqWZyzGgUox5C69R9H1IVN7xveD4Xti6wAyw+9cUfK0ChqtisdggMMQMn4GhEBic9zgkb3nIqWW52WY/ndl3OWmQm2Xuz5kNGdnnPuaZrIFmAM4P/e7/AFQu4j8Iea/XaOnxj6KsFGbPIyTQxpZnry3TPlwuF6kpqYRHhJfoDPiQQM9NZn/66CGYMze8+OKLzJ07lwMHDrgvLhEWFnbO/bRu3dr9OL+cISkp6azrb9++nV9//dUd8AICAhg4cCDTp093h9MNGzZwzz33FLn9hg0bsNlsXH311cV6n2cTFxdXIMgC7Ny5kyeffJLVq1eTnJzsnqkgISGBli1bsmHDBi699FJ3kD1T//79GTNmDPPnz2fQoEFMnz6d7t27U69evTK1VcRrnA6wBngvsJzJ5QJH+qnAlVN0GLNmpdIw6QCWzZkQWetU+LKHV5z3cj6Zx+HoTjO0FrjtNENpeTi649yv2+x5gbe6GbasAafdbGc8P21ZUChE1oHKdU/dB0ec+1hgvvf8AHtw/WkvWKBuJ2h+E8R1AkfmaSOsJwuPsJ4++hoYfCqo2c8IamcGt8AwsFrN0Gm15f0H4vTHebf855TgZ81qA5uHTlx3OvJ+J/J+P5zZZki1BZqfvy0QbEF5ywIKvuYrvx/noTB7HhaLpcxf9btcLnKDbIQGBXhtOqczQ+qrr77Ka6+9xpQpU2jVqhVhYWGMGzfuvBeLOHPWCIvFcs4rYU2bNo3c3Fxq1arlXmYYBoGBgRw/fpyoqChCQkLOuv25XgNziqkzS1WKOsGrqJB+ww03UKdOHd5//31q1qyJy+WiZcuW7s/gfMcOCgpi8ODBzJgxg5tvvplPPvlE05hJxeZyQdphOL4Hju/Ouz/tlnYYgiqdChyVTw8gcebzsGqe/QOYccwMUcl/ml8Z5z9OOWj+gS4GG9AS4EDBun8CQ4seYYysDdWaQJXGZtAqK5cTTuyFI9vNUVSn47Svec/xODfbrHk8+hdkHD37/i02iKoH4bHmZ2+4zBFbjHM/Dgw1A31QJXP0LSg8776I52D2f9phSD1U+D7rhBmSTiaYt7IKjsz72apb4GfNYo/ikkMLCPjgZTi86bTPwApxV5oBttkNZl+eQ2qWg4RjGew7lkFC3m3/8Uzz0DYbIRYbwYYVu8NGMDZCnDaCc6wEZ9oIDrQSHGgjyGZ1FxQYBhgYGIYTcGJAob89gTYrIYE27HnbBweY+woJyn9swx5gxWq15O3TIDvXRUaOk0yHk8ycXDJzXOZ5Ng4nmXnLM3KcZOe6yMm/OZ1kO1zkOE8ty3a63MucLhcWcty/plaLxRy4P+0xWLDmD+ifFsJP/9U+89c8f72xPRrRtEYx/jNSjhRmL1IrVqzgpptucn/973K5+Ouvv2jWrJnHjpGbm8uHH37Iq6++WugyxLfccgsff/wxY8aMoXXr1vz4448MGzas0D5atWqFy+Vi2bJl7pHc01WrVo3U1FTS09PdgTV/doxzOXr0KFu3buXdd9+lS5cuAPz0008F1mndujUffPABx44dO+vo7MiRI2nZsiVvv/02DoejUCmHSLnLSjGD1fG9p+7zw+qJvae+kjybnDQ4stW8FSUgxAyDleuagSIw1AyEgfm3EAgKy/uqNO8+KNQcGTq53wysyX+eCq3nCnH5LNa84HVmGKsE9nCctmASd22lZoQVa3oSpB42R20dGXmhfffZdgxRcVCtqRlu8++rXmIe60zOXHNfR7bl3bab98l/nf9zLY7wWKjSCKo0zLtvZAbuqDjPjeKVliPrVNhNO2wGcZcTXLmn3Zx5daVnLMtKMQPwiQQ4sQ8yj5kjpYc2mbfTBADuv0IWG9TvagbYptdDpYLfrh1JzWZHUhoJx9LzAmumO8AeS/f8VTw9xR5gxWa1kOlw4ovnCt/Rsa63m1CIwuxFqlGjRnzxxResWrWKqKgoJk+ezKFDhzwaZr/++muOHz/OiBEjiIyMLPDagAEDmDZtGmPGjOHpp5+mR48eNGzYkEGDBpGbm8u3337LI488Qr169bj77rsZPny4+wSwvXv3kpSUxG233UbHjh0JDQ3liSeeYOzYsfz6669Fnjh4pqioKKpUqcJ7771HbGwsCQkJPPbYYwXWuf3223nhhRfo378/kyZNIjY2lnXr1hEZGekO1s2aNeOKK67g0UcfZfjw4ecdzRUpM0dWXijYeyqg5gfXEwnm19XnYrGZYTSqnnmLrn/qcWQdyDxh7uvkvlPh40SC+TzlIORmmiOJR//y3HuKqAVVG5vBreolULWRORKcP6oYGHLO0WCXw8G6hQuJ6dsXa/63RznpRY8wph02P68j28xQlR/0//zujDblj942hPQjZnBN/sscVS2KzW62vXIdCLCf8TVvUBFf+eYtj6xlhtbohmZAr6gCg81QHRVX9n1lp+X9fO0r9LNmpBwkiapU6TqCgBY3Qmg0uU4Xu5PT2bLjAFsSU9iamMqWgykkp527PjQ6LIg60aHUjQ4lLjqU2lEhWK0Wsh1OshwushxOsnKdZOa4yMp1kuUwRzyzHOaIqMPpMkcj83708n8CTx/NPP3H0uF0kXn6vh0usvP2les6lVqzcwt/mxkUYI7qhgbZCAm0EXLGfXCgjaAAq3mzWbEHmLcCy/JGkwNsltNGksFlmKPAhZZh4Do9TJ+WrM/M2KeH7vpVz12O6A0KsxepJ598kt27d3PttdcSGhrKvffeS//+/Tl58qTHjjFt2jR69uxZKMiCOTL7wgsv8Ntvv9GtWzfmzZvHc889x4svvkhERARdu3Z1rzt16lSeeOIJRo8ezdGjR6lbty5PPPEEYM6FO3v2bB5++GHee+89evbsyTPPPMO99957zrZZrVbmzJnDAw88QMuWLWnSpAmvv/463bp1c68TFBTEokWLeOihh+jbty+5ubk0b96cF198scC+RowYwapVqxg+fHgZPi2Rs8g8AQmrYe9PsGclJG40R7/OJSTaDB2V88JH1OmBtfa5R/nCqpphsii5OZCy/1TATU8y6xUdmWZ4dGSaNa6OTMjJMEdGHRmn1omIPS2wNs4LsI3MkVxPCwrLG+FsePZ10pMLj7Ie2W4G3pT95m3njwW3CQw123/maG5UPbMOUgpwuQxynC53GDIwMAjGiGwMkY0x6hoFvsrPzM7hk//9QFR2S7Z/u5+tiVvYdii1yABosWAG1Sph1I0OIS46zB1e60SHEB5ccS6mlOt0kZWbH3KdOF3GqcAaaCPA5lPXsKpwLMZFNiFmSkoKkZGRnDx5koiIgjUfWVlZ7N69m/r163v0evUul4uUlBQiIiJ8+hKoUnRf/utf/2LOnDls2rTpPFtXHBfqZ92XOBwOFi5cSN++fSvWFQQzjsHeVbB3pTnv5KFNFBonCQrPC6t1TwVW933dor8i92Me78uMY2YJxJFt5klIYdVOhdbIOuZJQRVIRk4uyak5HEnLJjnvdiwtB4c5JJdX32mumz8yZz4+tdxigQCrBZvVgs1iwWaz5D23upe7X7dayMhxkpLlIDUrl1T3fcHHKVkO0rJzPfJVemiQjaY1wmleM4JmsRE0j42gSY1wj01fKZ5X1t/Lc+W1M+mnQKSU0tLS2Lp1K2+88YbHLvsr5cQwIHEDkRl7zK/OI2uYXw2Xp9wc86SajGOQvN0MrntWQtLmwutGNzBPfql3lXkfWdtvzkKukEKjoe4V5q2MXC4Dh8uFw2mQk+vCkXfSjsNpnqzjyDXIcTrJyTXynp92Ys/p6+a6SM/O5UhaDslp2RxNyyY573FGznlG6n1M5SCDtvWq0bJWZTO41owgLjrUfeKUyJkUZkVKacyYMXz66af0799fJQa+5uc3CVz0T7oBbDevOEhwpDkCd+atUt69PTxvAvW8ydMLTabuOu1xrnnSS+Yxs4Y187gZWjOPm2UDmcfOfaZ+1SZQ70ozuMZdaX4976MMwyA1O5cjqWZ9Y5DtVI1ffr1fgNVS5guNGAZkO5ycyHK5RwfTss2RwpTTRg3TsnLJznVhs1qwWizYrGCzWs17iwVr3gikNX+E0mohO+/r4fyzzrPyzz4/7Yzz/Psshxk+8wNorqt8vvwMDrRStZL9tFsQQQHmCLIFCny+Z9Z8WjBrKF2GQa7LhdNlkOs0zHtX/r2rwPOQQBvhwYGEBwcQERxAeHAgESEB7mWn7gMIDQrIa0Pe8YuoN81/7MzNJf777+jb97KK9Y2JVGgKsyKlNHPmzGKdbCYVTMJqiH8agKyACOzOdCyG89RclOeba9OjLBBS2TwBqm6nUyOvZ5y1fSHl5Lo4eCKTvccyOHA8E6sFcyqhwFMnnpgnolgLLAsOtJHrcpGUks3hlCwOp2RzKCWLpJQsDqVkuZcdTsk678ihxXIq5NoDrATmncSSP+ufYRjuE1bMk1hOP6EFnC4XaVk2nKt/PNdhKgSb1UKgzUKgzXyfp4f6QHfQt7gDf+Bp4T8kyGYG1XA71SoFnQqu4XbCgmx+ceVBh6euUiUXFYVZEbl4pB+Fz4eD4cTV4ma+D7yJvn37EJibbp6x7r4lm1dbOv15TtoZk6TbCk6YXuCxzZyAPSTavGpSSJT51XVIVN6yyubj4MrlUn95MtNBwlFzrs29x9LZdyyDvXnPD57IpDwGD8PtAVgsuL86P/2YhmGe4Z2d6yK11Ec4FeQq2QPco4LhwYGnPQ8kIjgAe6ANl8vAaZijjAVuhoErbwQyfx173pnmwXkn7ISedoZ5SJD5PD/o2wNsBUJ5oM1C4GnB1KavykU8TmFWRC4OLhfMvw9SDkCVRjj7vAo/rjDDZ2i0eavWxNutLBGH08WR1GySUs0R0KSUrFOPU7M5nJLNwROZnMw8y3RSeYIDrdSNDqV2VChWC6d9bX7q7Ov8ZWeeVR5ksxITaScmPJiYyGBiwoOpEWknJiKYmIhgakQEUz3CXuhEnVznGZO+n1Ejmusy3F+PF5zs/bRJ4C3m49zcXH5ZuZyb+vSicliIaitFLjIKsyJycVg5BXbEm9c5v3WWz53xbxgGy/9K5pNf9pJwLJOklCyOlmBi+KqV7Ob0RVXM6YviokOpW8W8rxZuL/ZX1C6XkTc3pxOrxULl0MBSfb0dYLMSYLMSGlTiTQtxOBz8ZYfw4EAFWZGLkMKsiPi/vatg8fPm474vQ42WUMRljysiwzD4cWsSbyz+i437C88DHWC1UD3cTvWIYKqHmyOi+ffVIuzERgZTJyqUMLtn/rm3Ws1LfGtKJBGpKPSvkYj4t7Qj7jpZWg+ESwd7u0XF4nIZLNpyiDcW72DzwRTALAe44/I4ul5SlerhwcRE2IkKDdJopIhc1BRmRcR/uVww/15ITTSv2tRvcoWfn9XpMli4KZE3F+9g+2HzdKjQIBuDO8VxT5cGVK1UzvPhiohUcBXrMibiVd26dWPcuHHu5/Xq1WPKlCnn3MZisfDVV1+V+die2o/4EZcTEn4x52strZ9ehZ2LISAkr062kufa52G5Thfz1++n92vLGPvperYfTiXcHsCY7o346dFreLxPMwVZEZEiaGTWD9xwww1kZmbyww8/FHrt559/pnPnzqxbt47LLrusRPtds2YNYWGevWb6M888w1dffcWGDRsKLE9MTCQqKsqjxzqbzMxMatasicVi4cCBA4SEhJTLcaUEdvxgzgV7+A8IrQJXPwbthkJACc4W2r0ClrxgPu73KsQ0vyBNLavsXCf/XX+Qt5buYO/RDAAiQwIZfmV9hl5Zj8gQTRwvInIuCrN+YMSIEdx8883s3buXuLi4Aq9Nnz6dtm3bljjIAlSrVn4Tt9eoUaPcjvXFF1/QsmVLDMPgyy+/5M477yy3Y5/JMAycTicBAfpVBCDxd4h/CnYtyVtggYyj8O3D8MtU6PkMNLvx/KUCaUnwxQjzilxt74RLvdfH+U5k5LDzSBo7j6Sb90np7DqSRsKxDPdVoqLDghhxVX2GdIojPFghVkSkOFRmcD6GATnpZb85Mkq+jVG8mcyvv/56qlevXuhqVBkZGcydO5cRI0Zw9OhRbr/9dmrXrk1oaCitWrXi008/Ped+zywz+Ouvv+jatSvBwcE0b96c+Pj4Qts8+uijXHLJJYSGhtKgQQOefPJJHHlnjc+cOZOJEyeyceNGc+5Ii8Xd5jPLDDZt2sQ111xDSEgIVapU4d577yUt7dTlP4cOHUr//v155ZVXiI2NpUqVKtx///3uY53LtGnTuOuuu7jrrruYNm1aodc3b95Mv379iIiIIDw8nC5durBz507367Nnz6ZVq1bY7XZiY2MZM2YMAHv27MFisRQYdT5x4gQWi4WlS5cCsHTpUiwWC99//z3t27fHbrezYsUKdu7cyU033URMTAyVKlWiQ4cOhUbas7OzeeSRR6hTpw52u53GjRszbdo0DMOgUaNGvPLKKwXW/+OPP7BarQXa7nEnEmDZy7DhU/NyraXezz6YPwre7WoGWWsgXHE//ONPc1Q1rBoc2wWfDYFpvc2reJ2NywlfjIS0w1CtqTl7QSmkZjn46a9k/vPDXwyZ/ivXTVnOzW+vZPC0X7jvo7X839wNTJi/iRcWbmXKD3/y/vJdfPzLXr5af4CFmxJ5f/kuHvvid25752faPRdP22fjuWXqzzzy+e+8u2wXP2w9zK7kdHJdBtXC7Uzo24yfHu3O/d0bKciKiJSAhoPOx5EBL9Qs0y6sQOXSbPjEQQg6/9f8AQEBDBkyhJkzZ/LUU0+553ycN28eOTk53HnnnWRkZNCuXTseffRRIiIi+Oabbxg8eDANGjSgY8eO5z2Gy+Xi5ptvpmrVqqxevZqUlJQC9bX5wsPDmTlzJjVr1mTTpk3cc889hIeH88gjjzBw4ED++OMPvvvuO3dQi4yMLLSPjIwMrrvuOq644grWrFlDUlISI0eOZMyYMQUC+5IlS4iNjWXJkiXs2LGDgQMH0rZtW+65556zvo+dO3fy888/8+WXX2IYBuPGjWPXrl00aNAAgAMHDtC1a1e6devG4sWLiYiIYOXKleTm5gIwdepUHn74YSZNmkTfvn05efIkK1euPO/nd6ZHHnmEV155hQYNGlC5cmX2799P3759ef755wkODmbWrFnccMMNbN++nbp16wIwZMgQfv75Z15//XXatGnD7t27SU5OxmKxMHz4cGbMmME//vEP9zGmT59Oly5daNiwYYnbd1652bDqDVj+CuRmmsssNqh3JTS9Hpr0hcp1zr+fzBPw02RY/Q44s81lLQdAjychqp75vMNIcxaCla/Dz2/C/l9h+rXmcXo+A1UbF9zn8ldg9zIIDDXrZIvxO2QYBgnHMli397j79ufhVI9fGatmZDANqlWiYbUwGlavRMNqlWhQLYwaEcF+cSlSERFvUJj1E8OHD+fll19m6dKldO/eHTDDzM0330xUVBRRUVEFgs7YsWP57rvvmDdvXrHC7A8//MDWrVvZs2cPtWvXBuCFF16gT58+Bdb75z//6X5cr149HnroIebOncsjjzxCSEgIlSpVIiAg4JxlBR9//DGZmZl8+OGH7prdN998kxtuuIF///vfxMTEABAVFcWbb76JzWajadOm9OvXjx9//PGcYXb69On06dPHXZ973XXXMX36dJ5/3pyD9K233iIyMpI5c+YQGGiOjl1yySXu7V944QXuv/9+HnjgAax5lyHt0KHDeT+/Mz377LP06tXL/bxKlSq0adPG/fz5559n/vz5LFiwgDFjxvDnn3/y2WefER8fT8+ePQHcARxg2LBhPPXUU/z6669cfvnlOBwOZs+ezcsvl25U8px2LoGF/4CjO8zntS83v0lI2gy7l5u3bx+B2DZm4Gx6PVRvVrA0IDcH1k6DZS9BZt6IbtxV0PtZqNWu8DHt4XDNBGg/HJZOgvUfwbavYfu30H4YXP0oVKoOu5aZrwNc/xpUb3rWt/HHgRR+PGDh6082sH7fCZLTCl+AoHZUCO3iomgXF0W9KmHuq2Cl5+SSkZ13n+MkPbvgfZbDSUxkMA3zg2u1StSvGuaxuV5FROQU/ct6PoGh5ghpGbhcLlJSU4kID3cHoGIfu5iaNm1K586dmT59Ot27d2fnzp2sWLGCRYsWAeB0OnnxxReZO3cuBw4cIDs7m+zs7GKf4LV161bq1q3rDrIAnTp1KrTe559/zpQpU9ixYwdpaWnk5uYSERFR7PeRf6w2bdoUaNuVV16Jy+Vi+/bt7jDbokULbDabe53Y2Fg2bdp01v06nU5mzZrFf/7zH/eyu+66i//7v/9j4sSJ2Gw2NmzYQJcuXdxB9nRJSUkcPHiQq6++ukTvpyjt27cv8Dw9PZ2JEyfy9ddfc/DgQXJzc8nMzCQhIQGADRs2YLPZznrs2NhY+vXrx/Tp07n88sv5+uuvycrK4tZbby1zW91SDsL3T8Dm+ebzsOpw7b+g1a1mUD22C7YthG3fQMLPkLjRvC35F0TVh6b9zGCbmgg/ToTje8z9VG0CvZ6FS649fy1sRCzc+Dpc8Xf44Rn48ztY8wFsnANXjIZ1MwHDnEu2zaCz7mb26r3886s/ABuQBJiXZW1ZK8IdXi+rG0X1iOCyfWYiInLBKcyej8VSrK8pz8nlgkCnuZ+ShNkSGjFiBGPGjOGtt95ixowZxMXF0aNHDwBeffVVXnvtNaZMmUKrVq0ICwtj3Lhx5OQU73KYRhH1u2d+Lbp69WoGDRrExIkTufbaa90jnK+++mqJ3odhGGf9yvX05WcGTovFgsvlOnMTt++//54DBw4wcODAAsudTieLFi2iT58+55zZ4HyzHuT/R+X0z+psNbxn/ifi4Ycf5vvvv+eVV16hUaNGhISEMGDAAHf/FGfGhZEjRzJ48GBee+01ZsyYwcCBAwkNLf5/iM7K6YBf3oGlL0JOGliscPm90P0JCD6tTCS6AXQeY97SjphBc9vX5kju8d1micDPb55av1KMuY+2d4GthP8UVW8Gd8w1ZyxY9E9I3ADLX8p7rcU562R3Hknj+W+2ANA00kX/Tk3pUL8qLWtFYA+wnXU7ERGpmHQCmB+57bbbsNlsfPLJJ8yaNYthw4a5w9+KFSu46aabuOuuu2jTpg0NGjTgr7/+Kva+mzdvTkJCAgcPnhql/vnnnwuss3LlSuLi4pgwYQLt27encePG7N27t8A6QUFBOJ3O8x5rw4YNpKenF9i31Wot8JV/SU2bNo1BgwaxYcOGArc777zTfSJY69atWbFiRZEhNDw8nHr16rFs2bIi958/+0NiYqJ72ZlTkJ3NihUrGDp0KH/7299o1aoVNWrUYM+ePe7XW7VqhcvlOuuxAfr27UtYWBhTp07l22+/Zfjw4cU69jntWQnvdDEDY06aWVJw7zLo8++CQfZMlarBZYPNwPnILrjtQ7PuNTgSgipBtyfggfXmdFslDbKnq98F7lkCt0yDynHmiWK3zoTAosN/rtPF+LkbyHK46NwwmvuauRhxZT3axUUpyIqI+CiNzPqRSpUqMXDgQJ544glOnjzJ0KFD3a81atSIL774glWrVhEVFcXkyZM5dOgQzZo1K9a+e/bsSZMmTRgyZAivvvoqKSkpTJgwocA6jRo1IiEhgTlz5tChQwe++eYb5s+fX2CdevXqsXv3bjZs2EDt2rUJDw/Hbi84Efydd97J008/zd13380zzzzDkSNHGDt2LIMHD3aXGJTUkSNH+N///seCBQto2bJlgdfuvvtu+vXrx5EjRxgzZgxvvPEGgwYN4vHHHycyMpLVq1dz+eWX06RJE5566ilGjx5NnTp16Nu3L6mpqaxcuZKxY8cSEhLCFVdcwYsvvki9evVITk4uUEN8Lo0aNeLLL7/khhtuwGKx8OSTTxYYZa5Xrx533303w4cPd58AtnfvXpKSkrjtttsAsNlsDB06lMcff5xGjRoVWQZSbKmHIf5J+H2u+Ty0CvScaE5zVdJvF+yVoPlN5s3lBCye/YbCaoVWA6DlLeYo8jnmon1ryU427j9JRHAAL/6tJetXLvZcO0RExCs0MutnRowYwfHjx+nZs6f7LHiAJ598kssuu4xrr72Wbt26UaNGDfr371/s/VqtVubPn092djaXX345I0eO5F//+leBdW666Sb+7//+jzFjxtC2bVtWrVrFk08+WWCdW265heuuu47u3btTrVq1IqcHCw0N5fvvv+fYsWN06NCBAQMG0KNHD958881C6xZX/slk+WUXp+vevTvh4eF89NFHVKlShcWLF5OWlsbVV19Nu3bteP/9990lDXfffTcvvPACU6dOpUWLFlx//fUFRrinT5+Ow+Ggffv2PPjgg+4Ty87ntddeIyoqis6dO3PDDTdw7bXXFpobeOrUqQwYMIDRo0fTtGlT7rnnngKj12D2f05OTtlGZTfOgTfb5wVZC7QbBmPWmiOtZQ2hVtuFK7WxWM4ZZH/ff4LXF5t99Vz/lsRGqh5WRMQfWIyiiiH9WEpKCpGRkZw8ebLQiUlZWVns3r2b+vXrExzsuT90LpeLlJQUIiIiSnYCmFQ4Fb0vV65cSbdu3di/f/85R7HP+rN+cAO8fw0YTohtC9dPLnp2AR+T5XDS7/UV7DySTr9Wsbx5x6Xk5uaycOFC+vbtW+QJf+I7HA6H+tJPqC/9R1n78lx57UwqMxDxA9nZ2ezbt48nn3yS2267rXTlGE4H/HeMGWSb3WjWnlr9o470399tY+eRdKqH23m+f0vN6Soi4kcq3tCSiJTYp59+SpMmTTh58iQvvfRS6Xby0xQ4vAlCoqHfZL8Jsit3JDNj5R4A/j2gNVFhZy9FEBER36MwK+IHhg4ditPpZN26ddSqVavkO0jaCsv+bT7u85I5G4EfOJnp4B/zNgJwR8e6dG9S3cstEhERT1OYFbnYuZzw3/vB5YBLrjNnBvATExdsJvFkFnFVQpnQt3gzd4iIiG9RmC3CRXZOnFyECvyMr34bDqwDe4R5CVg/qSf9dlMiX64/gNUCk29ro0vJioj4KYXZ0+SfbZeRkeHllohcWPk/44Gp+2Fx3vRhvZ+HiJpebJXnJKVk8cR889LGo65uSLu4aC+3SERELhQNVZzGZrNRuXJlkpLMa7WHhoZ65Kxnl8tFTk4OWVlZFXI6Jyk+X+9LwzDIyMggKSmJypGR2L4eCblZUP9quGyIt5vnEYZh8NiXmzie4aB5bATjepb+qnEiIlLxKcyeoUaNGgDuQOsJhmGQmZlJSEiIpgTycf7Sl5UrV6bG/m9g70oIDIMbX/eb8oI5a/axeFsSQTYrrw1sS1CA7/2nQ0REik9h9gwWi4XY2FiqV6+Ow+HwyD4dDgfLly+na9eumgTax/lDXwYGBmJLPQDxT5sLej4NUfW82iZP2Xs0nee+3gLAP669hCY1wr3cIhERudAUZs/CZrNhs3lmnk2bzUZubi7BwcE+G4DE5Bd9aRjwv3GQkwZ1roAO95TLYXOdLrYdSiUpNYvQoAAq2c1bWN59cKC1TKPdTpfBQ59tJCPHyeX1oxlxVQMPtl5ERCoqhVmRi82GT2Dnj2Czw01vwgWq/c3IyWVDwgnW7DnO2r3H+G3vcdJznGdd32a1EBpkKxRyA2wWbBYLVqt5b8t7brNasFos2Kxgs1o5kprF2r3HCQuy8eqtbbBZ/aNsQkREzk1hVuRiknoIvn/cfNz9Caja2GO7Tk7LZu2e46zZc4y1e47xx8EUnK6C09yF2wOIqxpKRo6T9Oxc0rOdpOfkYhjmyGpqVi6pWbllasfTN7SgTnRomfYhIiK+Q2FW5GJhGPDNQ5B1EmLbQqcxZdqd02Xw886jfP37QX7dfYxdyemF1omNDKZDvWg61Iuifb1oLokJLzRi6nIZZDqcpGXnkpadS7r73gy8DqcLl2HgdIHT5cLpMnAa+Y/Je80g12VQJyqEAe1ql+l9iYiIb1GYFblYbJ4P274GayD0fxtspfv135GUyhe/HeCr9QdIPJlV4LUmMeG0rxdFh3rRtK8XRe2o84+QWq0WwvLKCmJK1SIREbmYKcyKXAzSj8LCh83HXf8BMS1KtPnx9BwWbDzIl7/tZ+P+k+7lkSGBXN86lh7NqnNZ3SgqhwZ5stUiIiLnpTArcjH47lHISIbqLeCq8cXaJCfXxZLtSXyxbj9LtifhcJr1rwFWC92aVOOWy2pzTbPq2AM8M+uHiIhIaSjMiniDYUDKQTi4Hg7+Zt4n/wVXjYMOIz17rK3/g03zwGI1Zy8IOPfo6b5jGXywYhcLNh7keMapuZZb1org5ktrc2PbmlStZPdsG0VEREpJYVakPKQdyQuup4XXtMOF11v4CMS0hLpXeOa4x/fCf+83H1/5INS67JyrO10Gd3ywmn3HMgGoHm7nb5fW4ubLausCBCIiUiEpzIoUV/IOrKuncunerdj+9y1YbWDBHPHEYl4O9vTHWMzAenA9nNxXeH8WG1RvDjXbmiFz5xLYugA+Hw73rYCwKmVrr9Nh7ivrJNTuAN0nnHeTX3cfY9+xTCKCA3jjjsu4smEVAmy6HKyIiFRcCrMi5+PMhZ/fhKWTsOVmURfg2MoS7sRizula8zKoeakZXmNaQtBpZ/u3uhWStsDRHfDVKLh9btkuaPDjRDiwFoIj4ZZpYDv/Fcu+2XQQgGtb1ODqS6qV/tgiIiLlRGFW5FwO/WF+TZ+4AQBX/avZml2Dpk2amPOlGi7AAIPTHhunHtsjzPAa2waCI859LHs43DoLPugBfy2CVa+bNbSl8ef3sOoN8/FNb0NU3Hk3cboMvvvDLH3o1zq2dMcVEREpZ14Ps2+//TYvv/wyiYmJtGjRgilTptClS5ezrv/WW2/x5ptvsmfPHurWrcuECRMYMmRIObZYLgq52bD8FfhpMrhyzdHNa1/A2eI2dnz7LZd07ost8PwjnSVWoyX0+Tf870H48Vmzdrak9bMnD8D8UebjjqOg2fXF2uzX3cdITssmMiSQKxtVLWHDRUREvMOrxXBz585l3LhxTJgwgfXr19OlSxf69OlDQkJCketPnTqVxx9/nGeeeYbNmzczceJE7r//fv73v/+Vc8vFr+1fC+9eDctfMoNs0+vh/l/h0rvyamEvsMvuNksODKdZ85p+tPjbOnPhixGQecy8ylevZ4u96akSgxgCVScrIiI+wqt/sSZPnsyIESMYOXIkzZo1Y8qUKdSpU4epU6cWuf5HH33Efffdx8CBA2nQoAGDBg1ixIgR/Pvf/y7nlotfysmA7yfAtF5wZCuEVYNbZ8LA2RBeo/zaYbHA9a9BlUaQcsCsn3W5irft0hcg4WezvOHWGRBQvCm0zBKDQwD0baUSAxER8R1eKzPIyclh3bp1PPbYYwWW9+7dm1WrVhW5TXZ2NsHBwQWWhYSE8Ouvv+JwOAgs4mvf7OxssrOz3c9TUlIAcDgcOByOQutfCPnHKa/jSclZ9v6E7Zv/w3J8NwCuVrfh7Pk8hEZDbq57vXLrS2sw/G0aATOvxfLXIpw/vYar0wPn3MSyawm2FZOxALl9J2OE14FitnP1rmMkp+UQGRLA5XGRF8XPqn4v/Yf60n+oL/1HWfuyJNt5LcwmJyfjdDqJiSl4NfaYmBgOHTpU5DbXXnstH3zwAf379+eyyy5j3bp1TJ8+HYfDQXJyMrGxhUeUJk2axMSJEwstX7RoEaGh579uvCfFx8eX6/Hk/AKcGbQ4MJd6R5cAkBkYzYY6w0gKaANLV591u/Lqy7jY22m7bwaWxc+zep+LY5UuKXI9u+ME3bdNIACD3VWv4fc9QbBnYbGP89kuK2ClaaUc4r//zkOt9w36vfQf6kv/ob70H6Xty4yMjGKv6/UTwCxn1CAahlFoWb4nn3ySQ4cOccUVV2AYBjExMQwdOpSXXnoJm63oS2o+/vjjjB9/6vKdKSkp1KlTh969exMRcZ6zyz3E4XAQHx9Pr169ihw9Fi9x5RIwvReWo5sAcF42jIBrnqK9/ewXByj3vjT64PpvCtbNX3DVoenkjlwCoWfMP+tyYvvkFqy5qRjVW1B72IfUDgguen9FcLoMnn1pGZDDvX3a07XxxXHyl34v/Yf60n+oL/1HWfsy/5v04vBamK1atSo2m63QKGxSUlKh0dp8ISEhTJ8+nXfffZfDhw8TGxvLe++9R3h4OFWrFv0H2G63Y7cXrhsMDAws918UbxxTzuG3T+HwJgiJgoGzsdW7iqL/S1RYufbljf+BQxuxHN1B4NdjC88/u+QV2PsTBIZhuW0WgSElu1LXmp3JHE3PITIkkK5NLr6Tv/R76T/Ul/5Dfek/StuXJdnGa3+1goKCaNeuXaHh5/j4eDp37nzObQMDA6lduzY2m405c+Zw/fXXYy3L5PJy8XFkwtIXzcddH4Z6V3m3PeeSP/9sQPCp+Wfz7VoGy/JOgLxhinlhhhJauCkR0CwGIiLim7xaZjB+/HgGDx5M+/bt6dSpE++99x4JCQmMGmXOkfn4449z4MABPvzwQwD+/PNPfv31Vzp27Mjx48eZPHkyf/zxB7NmzfLm2xBftOYDc6aAiNrQfoS3W3N+Rc0/G90AvrwHMMxpw1rfVuLdnj6LQb/WNT3caBERkQvPq2F24MCBHD16lGeffZbExERatmzJwoULiYszr1aUmJhYYM5Zp9PJq6++yvbt2wkMDKR79+6sWrWKevXqeekdiE/KOgkrJpuPuz8OgcWvL/Wqy+6GPT/Bpnnm/LPRDSDtMFRrCn1eLtUuf9l9lOS0HCqHBtK5YZXzbyAiIlLBeP0EsNGjRzN69OgiX5s5c2aB582aNWP9+vXl0Crxa6veNC8qUPUSaD3I260pvvz5Zw+uh6M7zJHlgBBzLtyg0s3M8c3vZolB7+YqMRAREd+kv15SsaUchE9vh+nXQcaxsu8vLQl+fst8fM2TYPP6/+dK5vT6WYB+r0D1ZqXaldNl8P1mlRiIiIhv87G/5HJR2bYQ/jsaMo+bz7/6O9w+p2yXlF3xKjjSoeZl0OwGz7SzvNVoCSN/MIN+496l3o1KDERExB9oZFYqHkcWLHwE5txuBtmYlmCzw5/fweq3S7/f43thzTTzcc+nyxaKva1GK7jk2jK9h/wSg2ub11CJgYiI+Cz9BRPPcLnAMMq+nyN/wgc94dd3zeedxsA9i+Haf5nP45+GA+tKt++lL4LLAQ26mbeLWK7T5S4x6Nu68JXzREREfIXCrJRdejJ80ANejINvHoLEjSXfh2HAbx/Ce1ebFzIIrQp3zDNDbIAdOoyEZjeaYXTeMHNGgpI4vAU2fmo+7vFUydvnZ37dfUwlBiIi4hcUZqVsUg/BzH5w8DfIPmnO3/puV3inC/z6PmSeOP8+sk6aU00tGAuODHPU9O8r4ZLT6kEtFrjxDahcF07sNdctyUjw4ucBwwzEtdqV8E36n282qcRARET8g/6KSemdPAAz+sKRbRBeE26ZBi1vAVsQHPodFv4DXm0CX95nzo9aVPjctwbeuQo2fwnWAOj5DNw1H8JrFF43pDIMmGmut+W/sHZ68dq5bw1s/wYsVnMGg4vc6SUG/VRiICIiPk6zGUjpHN8Ls24wR0kj68LdCyC6PrQaYE6h9ftcs2wgaQv8Pse8RTeEywZDmzsgrBqsfA0W/wsMJ1SOgwHToXb7cx+3djvoOREWTYDvHoc6l5snQ52NYcAPz5iP294J1S7x2Efgq04vMeikEgMREfFxGpmVkju60xyRPbEXourDsIVmkM0XGg1X/B3+vgpG/mheuSqoEhzbaQbLyc3grQ7mZVkNpzmaO2rF+YNsvk73Q+NrwZkN84ZCdtrZ1935I+z9yZwNodtjZXnXfkMlBiIi4k/0l0xK5sh2M8im7DevoDXsW6hcp+h1LRYzoN74Ojy0HW58E2pfbgbYozsgMBRuesssTwiOLH4bLBboP9UsbTi6wyxnKIrLZQZmgMvvgcjaJXuvfijX6eK7P1RiICIi/kNlBlJ8h/6AD2+CjGSo3gKGfAWVqhdvW3sls8TgssGQtA3++h6a9IOqjUrXlrAqMGCaefLZxk+hfldoe0fBdbZ8Zc6sEBQOV40v3XH8zK+7j3E0XSUGIiLiPzQyK8VzcAPMut4MsrFtYOjXxQ+yZ6reFK58sPRBNl9cZ+j+hPn4m4fMUeN8TkfeDAZA57Fm+BW+zisxuK6FSgxERMQ/6K+ZnN/+tTDrRvNqXLXaw5AFZl1sRXDVeHMqL0eGWT/ryDSXb/jYrNENrQqdRnuzhRVGrtPF93klBn1bqcRARET8g8KsnNveVWZpQfZJqNsJBs83p8iqKKw2+Nt75uwISVvgu8fMQLv0RfP1rv8Ae7h321hB5JcYRKnEQERE/IjCrJzdrmUw+xbISTNrUu/6AoIjvN2qwsJj4Ob3AQusmwlz7oDURIisA+2He7t1FUZ+icG1KjEQERE/or9oUlhKojkLwCe3mV/fN+oJd3wGQWHebtnZNewOXR4yH+9cbN53f8K8FK6oxEBERPyWZjOQUw6uh9VT4Y8vweUwlzXpC7fO9I1Q2O1x2LsSEn6Gak2h9UBvt6jC+EUlBiIi4qcUZi92LidsXwg/vw0Jq04tr9sJrhgNTfuZdam+wBYAt86Cn16DS+/0nXaXg29UYiAiIn5KYfZilZ0K62fDL+/A8T3mMmsAtPibGWJrXebV5pVaeAz0edHbrahQTi8x0IUSRETE3yjMXmyO74Vf34PfPoTsFHNZSBS0G2ZeJSuipnfbJ2d16GQW6/Yez7sdI/FkVrG2cxnGqRKDBioxEBER/6Iwe7FwueDbh2HtdDBc5rIqjeGKv0Ob2yEo1LvtkwJynS62HUrlt4TjrN1jBtgDJzLLtM9bLqtNgEoMRETEzyjMXiwWPwdrPjAfN+gGV9xvzlJgVbipCJwug593HuXX3UdZl3CcDQknSM9xFljHaoFmsRG0i4uiXVwUDatVwmqxFGv/gTYLDatVuhBNFxER8SqF2YvB+tnw02Tzcf+p0PYO77ZH3HKdLhZsPMhbS3aw80h6gdfC7QFcGhdFu7pRtK8XRZs6lalk16+siIjI6fSX0d/tXg7/e9B83PVhBdkKIifXxfz1+3l76U72Hs0AICI4gJ7NYmhXzxx5bVw9HJu1eCOvIiIiFyuFWX+W/BfMHQyuXGhxM3R7wtstuuhl5zr5bO1+3lm6010DGx0WxIir6jOkUxzhwYFebqGIiIhvUZj1V+lH4eNbIesE1O4A/d9WfawXZeY4+fTXBN5dvpPDKdkAVK1k576uDbjzirqEBulXUUREpDT0F9Qf5WbD3Lvg+G6oXBcGfQKBId5u1UUpPTuX2av38v6KXSSn5QAQGxnMqKsbMrBDHYIDdWEHERGRslCY9TeGAQseMK/mZY+AOz6DStW93Sq/5nIZHM/I4VBKFkkp2RxKyeLQSfO2aMshjmeYlwauHRXC37s1ZEC72tgDFGJFREQ8QWHW3yx/BX6fAxYb3DoTqjfzdov8gmEYbDuUyoo/k1i528q3czZyJC2HQyezSErNwuE0zrptvSqhjO7eiL9dWkuXkhUREfEwhVl/sulzWPK8+bjfK9Coh3fb4wVOl8FPO5KpVslO45hKZQqPWQ4nq3cd5cetSSzelnTaRQuscOhwofWrVgqiengwNSKDiYmwExMRTNMa4fRsFqOLFYiIiFwgCrP+Yt+v8NVo83GnMdB+uHfb4wXZuU7GfrKeRVvMoBkUYKV5bASta0fSslYkrWtH0qhapXMGy6TULJZsS+LHrUn8tCOZjNMuXGAPsNKpQTS2tCQ6tW1GragwqkeY4bVaJTtBAQqsIiIi5U1h1h8c3wOf3g7ObGjSF3o96+0Wlbv07Fzu+2gdP+1IJshmxR5gJTU7lw37TrBh3wn3esGBZsBtVSuSVrUr06pWJA6ni8Xbkvhx62E27j9ZYL81IoK5pll1ejStTueGVQmwuFi4cCF9O8URGKhptERERLxNYdbXZZ6Aj2+DjGSo0Rpufh+sF9fJRSczHAyd+SvrE04QGmTjgyHtuaJBFfYey+D3/Sf448BJft9/ks0HU0jLzuW3hBP8lnAC2Fvk/trUjuSapjH0aFadFjUjsJx2yViHw1U+b0pERESKRWHWlzkdMG8oJG+H8Fi4Yy7YK3m7VeUqKTWLIdN+ZduhVCJDApk5rAOX1o0CoH7VMOpXDeOmtrUAc9aB3UfT3eF204GTbD5wEpcBVzWuSs9m1enepDrVI4K9+ZZERESkBBRmfdmv78GuJRAYagbZiJreblG52n88g7s++IU9RzOoFm5n9oiONKkRftb1rVYLDatVomG1SgUCrgG6bKyIiIiPUpj1VS6nGWYBej8HsW28255ytiMpjcHTfiHxZBa1o0L4eGRH4qqElXg/VoVYERERn6Yw66t2/GCe+BUcCW3u8HZrytUfB05y9/RfOZqeQ6PqlZg9oiM1IlUaICIicjFSmPVVv75v3l86GIJCvduWcrRmzzGGz1hDanYurWpFMmv45USHBXm7WSIiIuIlCrO+6OhO2BEPWC6q+WSXbk9i1Ox1ZDlcXF4/mml3tyc8WNNjiYiIXMwUZn3R2unmfaOeUKWhd9tSTr75PZFxc9fjcBp0b1KNqXe1Izjw4pqCTERERApTmPU1ORmw/iPz8eX3erct5eB4eg6frkngle+34zLg+taxTL6tra62JSIiIoDCrO/ZNA+yTkJUPXNk1g9lOZzEbznMfzccYOn2I+S6DABuv7wuz/dvqWm0RERExE1h1pcYxqkTvzqMBKv/jE46XQY/7zzKVxsO8N0fh0jLznW/1rJWBLdfXpc7Lq9b4GpcIiIiIgqzviRhNRzeBAEh0PZOb7emzAzDYPPBFL5af4AFGw+SlJrtfq12VAj929ai/6U1aVT97BdCEBERkYubwqwvWZM3KttqAIRGe7ctZZCUksW8dfuZv/4AO5LS3MsrhwbSr1Usf7u0Fu3iojQKKyIiIuelMOsrUg/Blv+ajy+/x7ttKQXDMFi39zizft7Lt5sS3XWwQQFWejWLof+ltbj6kmo6sUtERERKRGHWV6ybBa5cqNPRpy5dm5njZMHGA8xatZctiSnu5e3iohjYoQ7XtaxBhOaKFRERkVJSmPUFTsepuWV9ZDquhKMZzP5lL3PX7ONkpgMAe4CV/m1rMbhTHC1rRXq5hSIiIuIPFGZ9wbavIe0QhFWHZjd6uzVn5XIZrNiRzEc/7+HHbUkYZiUBdaJDGHxFHLe1r0PlUF16VkRERDxHYdYX5E/H1W4oBFS8MGgYBvPW7uedZTvZlZzuXt71kmrc3SmObk2qa25YERERuSC8frbN22+/Tf369QkODqZdu3asWLHinOt//PHHtGnThtDQUGJjYxk2bBhHjx4tp9Z6weHNsHclWGzQfpi3W1PIwROZDJn+K4988Tu7ktMJtwcw7Mp6LH7oaj4cfjk9msUoyIqIiMgF49UwO3fuXMaNG8eECRNYv349Xbp0oU+fPiQkJBS5/k8//cSQIUMYMWIEmzdvZt68eaxZs4aRI0eWc8vLUf6obLPrIaKmd9tyGsMw+GztPq59bTkr/komONDKE32bsvqJHjx9QwsaVKvk7SaKiIjIRcCrYXby5MmMGDGCkSNH0qxZM6ZMmUKdOnWYOnVqkeuvXr2aevXq8cADD1C/fn2uuuoq7rvvPtauXVvOLS8nmSfg97nm4wp04ldSShYjZ63lkc9/JzU7l0vrVmbhA124t2tDwuyqXBEREZHy47XkkZOTw7p163jssccKLO/duzerVq0qcpvOnTszYcIEFi5cSJ8+fUhKSuLzzz+nX79+Zz1OdnY22dmnriyVkmJOD+VwOHA4HB54J+eXf5ySHs/622xsjgyMas3IrXk5lFN7z8YwDL7edIiJX2/lZGYugTYL43o0YsSV9bBZLeX2eXpTaftSKh71pf9QX/oP9aX/KGtflmQ7i2Hkn3Nevg4ePEitWrVYuXIlnTt3di9/4YUXmDVrFtu3by9yu88//5xhw4aRlZVFbm4uN954I59//jmBgUXPVfrMM88wceLEQss/+eQTQkNDPfNmLgTDRY+tj1Ip+zAb6wxlT9VrvNqcNAd8tsvKxmPmYH7tMIM7GzmpWYE/QhEREfFNGRkZ3HHHHZw8eZKIiIhzruv174TPvGSpYRhnvYzpli1beOCBB3jqqae49tprSUxM5OGHH2bUqFFMmzatyG0ef/xxxo8f736ekpJCnTp16N2793k/HE9xOBzEx8fTq1evs4buM1l2LiZgw2EMezjNBz1D8yDv1aB+v/kwr/5vC8fSHQRYLYzu1oBRXesTaPP6+YPlrjR9KRWT+tJ/qC/9h/rSf5S1L/O/SS8Or4XZqlWrYrPZOHToUIHlSUlJxMTEFLnNpEmTuPLKK3n44YcBaN26NWFhYXTp0oXnn3+e2NjYQtvY7Xbsdnuh5YGBgeX+i1KiY/42AwBL2zsJDIu6gK06u5MZDp5e8AdfbTgIQJOYcF69rY0ueIB3fn7kwlBf+g/1pf9QX/qP0vZlSbbx2tBaUFAQ7dq1Iz4+vsDy+Pj4AmUHp8vIyMBqLdhkm80GmCO6fuP4HvjzO/NxB+/M1LA+4Ti9pyzjqw0HsVpgdLeGLBh7pYKsiIiIVCheLTMYP348gwcPpn379nTq1In33nuPhIQERo0aBZglAgcOHODDDz8E4IYbbuCee+5h6tSp7jKDcePGcfnll1OzZsWZtqrM1k4HDGh4DVRtXO6H/2XXUYbPXEN6jpMG1cJ49dY2XFrXO6PDIiIiIufi1TA7cOBAjh49yrPPPktiYiItW7Zk4cKFxMXFAZCYmFhgztmhQ4eSmprKm2++yUMPPUTlypW55ppr+Pe//+2tt+B5jkz4zQzvdLin3A//01/JjPxwDVkOF50bVuH9Ie013ZaIiIhUWF5PKaNHj2b06NFFvjZz5sxCy8aOHcvYsWMvcKu86I8vIfM4RNaFS64t10Mv3naYUbN/IyfXRbcm1XjnrnYEB9rKtQ0iIiIiJeH1MCtnWPOBed9hOFjLL0h+90ciYz9dj8Np0Lt5DG/ccSn2AAVZERERqdgUZiuSzBNw8Dfzcds7y+2w/91wgPGfbcTpMrihTU0m39bmopx2S0RERHyPwmxFcmiTeR9ZFypVL5dDfrZmH49++TuGAQPa1ebft7TGZi16nl8RERGRikZhtiI59Lt5H9u6XA734c97eOq/mwG4s2NdnrupJVYFWREREfEhCrMVSWJemK1x4cPs+8t38a+FWwEYfmV9nry+2VmvvCYiIiJSUSnMViTlNDL7xo9/8Wr8nwDc370h/+jdREFWREREfJLCbEXhyIQj283HF2hk1jAMXlm0nbeW7ATgoV6XMLZH+V+UQURERMRTFGYriqQtYDghtApEXJirmb30/XamLjWD7IS+zbina4MLchwRERGR8qIwW1GcXi97Ab7y33zwpDvIPntTC4Z0qufxY4iIiIiUN00mWlFc4HrZVxeZNbI3tKmpICsiIiJ+Q2G2okjcaN5fgHrZdXuPsXhbEjarhf/rqRpZERER8R8KsxWBMxcOm/O9EtvGo7s2DIOXvjNPLBtwWW0aVKvk0f2LiIiIeJPCbEVw9C/IzYLAMIhu6NFd/7QjmV92HyPIZuUBjcqKiIiIn1GYrQjcJ3+1AqvnusQwDF753hyVvfOKutSqHOKxfYuIiIhUBAqzFcEFOvlr0ZbDbNx/ktAgG6O7NfLovkVEREQqAoXZiuACnPzldBm8usgclR12ZT2qhds9tm8RERGRikJh1tsM44KMzC7YeIA/D6cRERzAvV08W4crIiIiUlEozHrbiQTIOgnWQKjWzCO7dDhdvBb/FwD3Xd2QyNBAj+xXREREpKJRmPW2/FHZ6k0hIMgju/xs7T4SjmVQtVIQw66s55F9ioiIiFRECrPe5p7JwDPzy2Y5nLz+ozkqe3/3RoQG6YrFIiIi4r8UZr3Nw/Wys1fv5XBKNjUjg7mjY12P7FNERESkolKY9Tb3yGzZw2xqloO3luwAYFzPS7AH2Mq8TxEREZGKTGHWm9KTIfUgYIEaLcu8u+k/7eF4hoMGVcO4+bJaZW+fiIiISAWnMOtN+fPLRjcAe3iZdnU8PYcPVuwC4P96XUKATV0rIiIi/k+Jx5vyw2xs2U/+emf5TlKzc2kWG0G/VrFl3p+IiIiILyhxmK1Xrx7PPvssCQkJF6I9FxcPnfx1OCWLWav2APDwtZdgtVrK2DARERER31DiMPvQQw/x3//+lwYNGtCrVy/mzJlDdnb2hWib//PQyV9vLt5BlsNFu7goujep7oGGiYiIiPiGEofZsWPHsm7dOtatW0fz5s154IEHiI2NZcyYMfz2228Xoo3+KTsVju00H5ehzGDfsQzmrDFHyf/RuwkWi0ZlRURE5OJR6prZNm3a8J///IcDBw7w9NNP88EHH9ChQwfatGnD9OnTMQzDk+30P4f+MO/Da0JY1VLvZsoPf+FwGnRpXJVODat4qHEiIiIivqHUl4dyOBzMnz+fGTNmEB8fzxVXXMGIESM4ePAgEyZM4IcffuCTTz7xZFv9iwfqZXckpTJ//X7AHJUVERERudiUOMz+9ttvzJgxg08//RSbzcbgwYN57bXXaNq0qXud3r1707VrV4821O94oF72i98O4DKgZ7PqtKlT2TPtEhEREfEhJQ6zHTp0oFevXkydOpX+/fsTGBhYaJ3mzZszaNAgjzTQbx3Kn5ar9GH2551HAbiupabiEhERkYtTicPsrl27iIuLO+c6YWFhzJgxo9SN8nu5OZC0zXxcypHZtOxcNh04CaBaWREREblolfgEsKSkJH755ZdCy3/55RfWrl3rkUb5vSNbweWA4MpQuW6pdrFm9zGcLoO60aHUqhzi2faJiIiI+IgSh9n777+fffv2FVp+4MAB7r//fo80yu+562VbQSmn0lq9yywx6NRAo7IiIiJy8SpxmN2yZQuXXXZZoeWXXnopW7Zs8Uij/J57JoPSzy/7c36YVYmBiIiIXMRKHGbtdjuHDx8utDwxMZGAgFLP9HVxSSxbmE3JcvBHXr3sFRqZFRERkYtYicNsr169ePzxxzl58qR72YkTJ3jiiSfo1auXRxvnl1wuOLTJfFzKk79+3XUMlwH1q4ZRIzLYg40TERER8S0lHkp99dVX6dq1K3FxcVx66aUAbNiwgZiYGD766COPN9DvHNsJjnQICIGqjUu1i/wSA43KioiIyMWuxGG2Vq1a/P7773z88cds3LiRkJAQhg0bxu23317knLNyhsS8+WVjWoDVVqpd5M8vq3pZERERudiVqsg1LCyMe++919NtuTiU8TK2JzJy2HooBYArGkR7qlUiIiIiPqnUZ2xt2bKFhIQEcnJyCiy/8cYby9wov1bGy9iu3nUMw4BG1StRPVz1siIiInJxK9UVwP72t7+xadMmLBYLhmEAYMmbL9XpdHq2hf7EMMo8Mqv5ZUVEREROKfFsBg8++CD169fn8OHDhIaGsnnzZpYvX0779u1ZunTpBWiiH0lNhIyjYLFB9Ral2sVqzS8rIiIi4lbikdmff/6ZxYsXU61aNaxWK1arlauuuopJkybxwAMPsH79+gvRTr9gyR+VrdYEAkteInA0LZtth1IB6Fhf9bIiIiIiJR6ZdTqdVKpUCYCqVaty8OBBAOLi4ti+fbtnW+dnLIfLNr/sL7uPAdAkJpwqleyeapaIiIiIzyrxyGzLli35/fffadCgAR07duSll14iKCiI9957jwYNGlyINvoNS/7FEkp55S9NySUiIiJSUInD7D//+U/S09MBeP7557n++uvp0qULVapUYe7cuR5voD9xj8yW8uQvXSxBREREpKASh9lrr73W/bhBgwZs2bKFY8eOERUV5Z7RQAoLzE3DcnKf+aRGqxJvn5SaxY6kNCwWzS8rIiIikq9ENbO5ubkEBATwxx9/FFgeHR1d6iD79ttvU79+fYKDg2nXrh0rVqw467pDhw7FYrEUurVoUbqZAcpTZGaC+SCqHgRHlnj71bvMetlmNSKoHBrkwZaJiIiI+K4ShdmAgADi4uI8Npfs3LlzGTduHBMmTGD9+vV06dKFPn36kJCQUOT6//nPf0hMTHTf9u3bR3R0NLfeeqtH2nMhRWbsNR+U8uQv1cuKiIiIFFbi2Qz++c9/8vjjj3Ps2LEyH3zy5MmMGDGCkSNH0qxZM6ZMmUKdOnWYOnVqketHRkZSo0YN923t2rUcP36cYcOGlbktF1pkZl6Y1cUSRERERDymxDWzr7/+Ojt27KBmzZrExcURFhZW4PXffvutWPvJyclh3bp1PPbYYwWW9+7dm1WrVhVrH9OmTaNnz57ExcWddZ3s7Gyys7Pdz1NSUgBwOBw4HI5iHaesHA4HlTP3AJBbrQVGCY97KCWL3cnpWC1wae3wcmu3FJb/2asPfJ/60n+oL/2H+tJ/lLUvS7JdicNs//79S7pJkZKTk3E6ncTExBRYHhMTw6FDh867fWJiIt9++y2ffPLJOdebNGkSEydOLLR80aJFhIaGlqzRpWRzZdMvKxGAHzYfIfvPhSXafu0RC2CjVqjBT0viL0ALpaTi49UP/kJ96T/Ul/5Dfek/StuXGRkZxV63xGH26aefLukm53TmiWOGYRTrZLKZM2dSuXLl84brxx9/nPHjx7ufp6SkUKdOHXr37k1ERESp2lxSzr2rsWw0MMKq0eOmO0q8/U9fbQYO0LttPfpe18TzDZRiczgcxMfH06tXLwIDA73dHCkD9aX/UF/6D/Wl/yhrX+Z/k14cJQ6znlK1alVsNluhUdikpKRCo7VnMgyD6dOnM3jwYIKCzn1mv91ux24vfLWswMDAcvtFsSZvAcCIaV2qY/6y+zgAVzWurl/uCqI8f37kwlJf+g/1pf9QX/qP0vZlSbYp8QlgVqsVm8121ltxBQUF0a5du0LDz/Hx8XTu3Pmc2y5btowdO3YwYsSIkjbfK/Kv/GWUYn7ZAycySTiWgc1qoUN9zS8rIiIicroSj8zOnz+/wHOHw8H69euZNWtWkbWp5zJ+/HgGDx5M+/bt6dSpE++99x4JCQmMGjUKMEsEDhw4wIcfflhgu2nTptGxY0datmxZ0uZ7x+H8MFvymQzyp+RqVSuSSnavDaSLiIiIVEglTkc33XRToWUDBgygRYsWzJ07t0SjpQMHDuTo0aM8++yzJCYm0rJlSxYuXOienSAxMbHQnLMnT57kiy++4D//+U9Jm+4dTgeWpK1A6UZmNb+siIiIyNl5bKivY8eO3HPPPSXebvTo0YwePbrI12bOnFloWWRkZInOcPO65D+xOLNxWEOg8tmnECuKYRiaX1ZERETkHEpcM1uUzMxM3njjDWrXru2J3fmXxN8BOBlaFywl+7j3HcvkwIlMAm0W2teLuhCtExEREfFpJR6ZjYqKKjB1lmEYpKamEhoayuzZsz3aOL9wZBsAJ0PiiCzhpj/vSgagTe3KhAapXlZERETkTCVOSK+99lqBMGu1WqlWrRodO3YkKkqjh4X0fAbHpXezY8lS6pZw0/x62StUYiAiIiJSpBKH2aFDh16AZvgxiwUi65AVVLJAatbLHgN08peIiIjI2ZS4ZnbGjBnMmzev0PJ58+Yxa9YsjzRKYM/RDA6lZBFks9IuTiPeIiIiIkUpcZh98cUXqVq1aqHl1atX54UXXvBIo+RUiUHbupUJDiz+xShERERELiYlDrN79+6lfv36hZbHxcUVmhNWSu9nTcklIiIicl4lDrPVq1fn999/L7R848aNVKmi4OUJhmHoYgkiIiIixVDiMDto0CAeeOABlixZgtPpxOl0snjxYh588EEGDRp0Idp40dl5JI3ktGzsAVYurVvZ280RERERqbBKPJvB888/z969e+nRowcBAebmLpeLIUOGqGbWQ/JHZdvFRWEPUL2siIiIyNmUOMwGBQUxd+5cnn/+eTZs2EBISAitWrUiLq5kl2qVs1O9rIiIiEjxlPqyUo0bN6Zx48aebIsALtep+WWvUL2siIiIyDmVuGZ2wIABvPjii4WWv/zyy9x6660eadTF7M+kVI6l5xASaKNN7crebo6IiIhIhVbiMLts2TL69etXaPl1113H8uXLPdKoi9nqvHrZ9vWiCAoocfeIiIiIXFRKnJbS0tIICgoqtDwwMJCUlBSPNOpill8ve4XqZUVERETOq8RhtmXLlsydO7fQ8jlz5tC8eXOPNOpitnbPcUBhVkRERKQ4SnwC2JNPPsktt9zCzp07ueaaawD48ccf+eSTT/j888893sCLSU6ui6PpOQA0qBrm5daIiIiIVHwlDrM33ngjX331FS+88AKff/45ISEhtGnThsWLFxMREXEh2njROJFhBlmLBSJCAr3cGhEREZGKr1RTc/Xr1899EtiJEyf4+OOPGTduHBs3bsTpdHq0gReT4xkOACqHBGKzWrzcGhEREZGKr9Snyy9evJi77rqLmjVr8uabb9K3b1/Wrl3rybZddI7njcxGhRY+wU5ERERECivRyOz+/fuZOXMm06dPJz09ndtuuw2Hw8EXX3yhk7884HhevWzlUJUYiIiIiBRHsUdm+/btS/PmzdmyZQtvvPEGBw8e5I033riQbbvo5JcZRIdpZFZERESkOIo9Mrto0SIeeOAB/v73v+sythdIfplBZZUZiIiIiBRLsUdmV6xYQWpqKu3bt6djx468+eabHDly5EK27aKTX2YQpTIDERERkWIpdpjt1KkT77//PomJidx3333MmTOHWrVq4XK5iI+PJzU19UK286Lgns1AI7MiIiIixVLi2QxCQ0MZPnw4P/30E5s2beKhhx7ixRdfpHr16tx4440Xoo0Xjfx5ZlUzKyIiIlI8pZ6aC6BJkya89NJL7N+/n08//dRTbbponZqaS2UGIiIiIsVRpjCbz2az0b9/fxYsWOCJ3V20VGYgIiIiUjIeCbPiGcdVZiAiIiJSIgqzFYTTZXAyM39kVmUGIiIiIsWhMFtBnMx0YBjm48ohGpkVERERKQ6F2Qoiv8Qg3B5AUIC6RURERKQ4lJoqiPxpuSqHqcRAREREpLgUZiuIY+lmvWyUZjIQERERKTaF2Qri1ByzCrMiIiIixaUwW0Gc0AUTREREREpMYbaCyC8z0AUTRERERIpPYbaCOKEyAxEREZESU5itIE5d/UtlBiIiIiLFpTBbQRzPUJmBiIiISEkpzFYQx9NVZiAiIiJSUgqzFUT+yGyUygxEREREik1htgIwDEMngImIiIiUgsJsBZCanUuuywAUZkVERERKQmG2AjiRN8dscKCVkCCbl1sjIiIi4jsUZisAXcpWREREpHQUZiuAY3lhVtNyiYiIiJSMwmwFcEIXTBAREREpFYXZCuB4ui6YICIiIlIaCrMVwKlpuTQyKyIiIlISXg+zb7/9NvXr1yc4OJh27dqxYsWKc66fnZ3NhAkTiIuLw26307BhQ6ZPn15Orb0wjukEMBEREZFSCfDmwefOncu4ceN4++23ufLKK3n33Xfp06cPW7ZsoW7dukVuc9ttt3H48GGmTZtGo0aNSEpKIjc3t5xb7lnuq38pzIqIiIiUiFfD7OTJkxkxYgQjR44EYMqUKXz//fdMnTqVSZMmFVr/u+++Y9myZezatYvo6GgA6tWrV55NviDcZQY6AUxERESkRLwWZnNycli3bh2PPfZYgeW9e/dm1apVRW6zYMEC2rdvz0svvcRHH31EWFgYN954I8899xwhISFFbpOdnU12drb7eUpKCgAOhwOHw+Ghd3Nu+cc52/GOpplhNjzIWm5tktI5X1+K71Bf+g/1pf9QX/qPsvZlSbbzWphNTk7G6XQSExNTYHlMTAyHDh0qcptdu3bx008/ERwczPz580lOTmb06NEcO3bsrHWzkyZNYuLEiYWWL1q0iNDQ0LK/kRKIj48vcvmhYzbAwpYNa0jfUa5NklI6W1+K71Ff+g/1pf9QX/qP0vZlRkZGsdf1apkBgMViKfDcMIxCy/K5XC4sFgsff/wxkZGRgFmqMGDAAN56660iR2cff/xxxo8f736ekpJCnTp16N27NxERER58J2fncDiIj4+nV69eBAYWLiV4dO0PgIt+PbtRN7p8A7aUzPn6UnyH+tJ/qC/9h/rSf5S1L/O/SS8Or4XZqlWrYrPZCo3CJiUlFRqtzRcbG0utWrXcQRagWbNmGIbB/v37ady4caFt7HY7dru90PLAwMBy/0Up6piZOU6yHC4AqkWG6pfXR3jj50cuDPWl/1Bf+g/1pf8obV+WZBuvTc0VFBREu3btCg0/x8fH07lz5yK3ufLKKzl48CBpaWnuZX/++SdWq5XatWtf0PZeKMfzTv4KsFoIt3t9oFxERETEp3h1ntnx48fzwQcfMH36dLZu3cr//d//kZCQwKhRowCzRGDIkCHu9e+44w6qVKnCsGHD2LJlC8uXL+fhhx9m+PDhZz0BrKLLD7OVQ4POWl4hIiIiIkXz6lDgwIEDOXr0KM8++yyJiYm0bNmShQsXEhcXB0BiYiIJCQnu9StVqkR8fDxjx46lffv2VKlShdtuu43nn3/eW2+hzPIvZaurf4mIiIiUnNe/1x49ejSjR48u8rWZM2cWWta0aVO/OsvxuHuOWV0wQURERKSkvH4524ud+4IJGpkVERERKTGFWS/TpWxFRERESk9h1suOpavMQERERKS0FGa9TGUGIiIiIqWnMOtl+WUGlVVmICIiIlJiCrNe5p7NQGFWREREpMQUZr0sP8xGh6nMQERERKSkFGa97ES6ygxERERESkth1otycl2kZucCKjMQERERKQ2FWS86kWmWGFgsEBmiMgMRERGRklKY9aITeTMZRIYEYrNavNwaEREREd+jMOtFx9M1k4GIiIhIWSjMetFxXTBBREREpEwUZr0o/4IJGpkVERERKR2FWS/KH5nVtFwiIiIipaMw60X5NbO6YIKIiIhI6SjMelF+mYFGZkVERERKR2HWi05kaDYDERERkbJQmPWiY+mazUBERESkLBRmvSj/oglRYRqZFRERESkNhVkvOq4yAxEREZEyUZj1EqfL4ERm/jyzKjMQERERKQ2FWS9JyXRgGOZjzWYgIiIiUjoKs16SX2JQyR5AUIC6QURERKQ0lKK85NQcsyoxEBERESkthVkvOXX1L5UYiIiIiJSWwqyX5JcZqF5WREREpPQUZr3EPcesygxERERESk1h1kuOaY5ZERERkTJTmPWSEwqzIiIiImWmMOslx9PzL2WrMgMRERGR0lKY9ZJjOgFMREREpMwUZr0kv8wgWmFWREREpNQUZr1EF00QERERKTuFWS8wDOPUCWC6aIKIiIhIqSnMekFadi4OpwGozEBERESkLBRmvSD/ggn2ACshQTYvt0ZERETEdynMesFxzTErIiIi4hEKs15wLF31siIiIiKeoDDrBfllBlGayUBERESkTBRmvUBlBiIiIiKeoTDrBcfdZQYamRUREREpC4VZLzjuLjPQyKyIiIhIWSjMekF+mUFlhVkRERGRMlGY9QKdACYiIiLiGQqzXqCpuUREREQ8Q2HWC05oNgMRERERj1CY9YLjKjMQERER8QiF2XKW5XCS6XACKjMQERERKSuvh9m3336b+vXrExwcTLt27VixYsVZ1126dCkWi6XQbdu2beXY4rLJn8kgwGoh3B7g5daIiIiI+Davhtm5c+cybtw4JkyYwPr16+nSpQt9+vQhISHhnNtt376dxMRE961x48bl1OKyO55ulhhUDg3EYrF4uTUiIiIivs2rYXby5MmMGDGCkSNH0qxZM6ZMmUKdOnWYOnXqOberXr06NWrUcN9sNls5tbjsdClbEREREc/x2vfcOTk5rFu3jscee6zA8t69e7Nq1apzbnvppZeSlZVF8+bN+ec//0n37t3Pum52djbZ2dnu5ykpKQA4HA4cDkcZ3kHx5R/H4XCQnJIJQGRIQLkdXzzn9L4U36a+9B/qS/+hvvQfZe3LkmzntTCbnJyM0+kkJiamwPKYmBgOHTpU5DaxsbG89957tGvXjuzsbD766CN69OjB0qVL6dq1a5HbTJo0iYkTJxZavmjRIkJDQ8v+RkogPj6enw5ZABvZKcdYuHBhuR5fPCc+Pt7bTRAPUV/6D/Wl/1Bf+o/S9mVGRkax1/X6GUhn1o0ahnHWWtImTZrQpEkT9/NOnTqxb98+XnnllbOG2ccff5zx48e7n6ekpFCnTh169+5NRESEB97B+TkcDuLj4+nVqxe7fkqA3Ttp1qAOffu2KJfji+ec3peBgZpazZepL/2H+tJ/qC/9R1n7Mv+b9OLwWpitWrUqNput0ChsUlJSodHac7niiiuYPXv2WV+32+3Y7fZCywMDA8v9FyUwMJCUbHNaruhKwfpF9WHe+PmRC0N96T/Ul/5Dfek/StuXJdnGayeABQUF0a5du0LDz/Hx8XTu3LnY+1m/fj2xsbGebt4Fc0IXTBARERHxGK+WGYwfP57BgwfTvn17OnXqxHvvvUdCQgKjRo0CzBKBAwcO8OGHHwIwZcoU6tWrR4sWLcjJyWH27Nl88cUXfPHFF958GyWi2QxEREREPMerYXbgwIEcPXqUZ599lsTERFq2bMnChQuJi4sDIDExscCcszk5OfzjH//gwIEDhISE0KJFC7755hv69u3rrbdQYsfT88Ksrv4lIiIiUmZePwFs9OjRjB49usjXZs6cWeD5I488wiOPPFIOrbpwjqvMQERERMRjvH4524tNfplBZZUZiIiIiJSZwmw5cjhdpGblAhCtMgMRERGRMlOYLUcnM80SA4sFIkNUZiAiIiJSVgqz5Si/XjYiOBCbtegLQ4iIiIhI8SnMlqP8elmVGIiIiIh4hsJsOcq/YEJlzWQgIiIi4hEKs+Xo1NW/NDIrIiIi4gkKs+XouMKsiIiIiEcpzJajU5eyVZmBiIiIiCcozJajE3lTc+lStiIiIiKeoTBbjlQzKyIiIuJZCrPl6FTNrMoMRERERDxBYbYcncirma2skVkRERERj1CYLUfukdkwjcyKiIiIeILCbDlxGXAy7wSwaI3MioiIiHiEwmw5ycw1Ay2ozEBERETEUxRmy0l6rnkfFmQjKEAfu4iIiIgnKFWVk/wwqzlmRURERDxHYbacpOdaAM0xKyIiIuJJCrPlJG8iAyprjlkRERERj1GYLSf5ZQbRKjMQERER8RiF2XKSpjIDEREREY9TmC0nKjMQERER8TyF2XKiMgMRERERz1OYLSf5sxnoggkiIiIinqMwW07S88oMolRmICIiIuIxCrPlxH3RBI3MioiIiHiMwmw5MAxDVwATERERuQAUZstBeo4Tp5E/NZfKDEREREQ8RWG2HJzIm5crKMBKSKDNy60RERER8R8Ks+UgP8xGhQZisVi83BoRERER/6EwWw6OZ+QAEBWiEgMRERERT1KYLQfH80ZmdfUvEREREc9SmC0HJzLzyww0k4GIiIiIJynMloPj6WaZgUZmRURERDxLYbYc5I/MKsyKiIiIeJbCbDk4nqEyAxEREZELQWG2HLhnM9DIrIiIiIhHKcyWgxOazUBERETkglCYLQfuMKt5ZkVEREQ8SmG2HLjLDMJUMysiIiLiSQqzF1iWw0mmwwXoCmAiIiIinqYwe4HllxhYMQgPDvBya0RERET8i8LsBZZfYhAaCBaLxcutEREREfEvCrMXWP7Vv8I0KCsiIiLicQqzF1j+BRMUZkVEREQ8T2H2AssvMwgLMLzcEhERERH/ozB7gbnLDDSRgYiIiIjH6cvvC2xA+9q0rhXO5t9+8XZTRERERPyO10dm3377berXr09wcDDt2rVjxYoVxdpu5cqVBAQE0LZt2wvbwDKKjQyhc8Mq1ArzdktERERE/I9Xw+zcuXMZN24cEyZMYP369XTp0oU+ffqQkJBwzu1OnjzJkCFD6NGjRzm1VEREREQqIq+G2cmTJzNixAhGjhxJs2bNmDJlCnXq1GHq1Knn3O6+++7jjjvuoFOnTuXUUhERERGpiLxWM5uTk8O6det47LHHCizv3bs3q1atOut2M2bMYOfOncyePZvnn3/+vMfJzs4mOzvb/TwlJQUAh8OBw+EoZetLJv845XU8uXDUl/5Dfek/1Jf+Q33pP8ralyXZzmthNjk5GafTSUxMTIHlMTExHDp0qMht/vrrLx577DFWrFhBQEDxmj5p0iQmTpxYaPmiRYsIDQ0tecPLID4+vlyPJxeO+tJ/qC/9h/rSf6gv/Udp+zIjI6PY63p9NoMzL/FqGEaRl311Op3ccccdTJw4kUsuuaTY+3/88ccZP368+3lKSgp16tShd+/eRERElL7hJeBwOIiPj6dXr14EBmqOLl+mvvQf6kv/ob70H+pL/1HWvsz/Jr04vBZmq1atis1mKzQKm5SUVGi0FiA1NZW1a9eyfv16xowZA4DL5cIwDAICAli0aBHXXHNNoe3sdjt2u73Q8sDAwHL/RfHGMeXCUF/6D/Wl/1Bf+g/1pf8obV+WZBuvnQAWFBREu3btCg0/x8fH07lz50LrR0REsGnTJjZs2OC+jRo1iiZNmrBhwwY6duxYXk0XERERkQrCq2UG48ePZ/DgwbRv355OnTrx3nvvkZCQwKhRowCzRODAgQN8+OGHWK1WWrZsWWD76tWrExwcXGi5iIiIiFwcvBpmBw4cyNGjR3n22WdJTEykZcuWLFy4kLi4OAASExPPO+esiIiIiFy8vH4C2OjRoxk9enSRr82cOfOc2z7zzDM888wznm+UiIiIiPgEr1/OVkRERESktBRmRURERMRnKcyKiIiIiM9SmBURERERn+X1E8DKm2EYQMmuLFFWDoeDjIwMUlJSNAm0j1Nf+g/1pf9QX/oP9aX/KGtf5ue0/Nx2LhddmE1NTQWgTp06Xm6JiIiIiJxLamoqkZGR51zHYhQn8voRl8vFwYMHCQ8Px2KxlMsxU1JSqFOnDvv27SMiIqJcjikXhvrSf6gv/Yf60n+oL/1HWfvSMAxSU1OpWbMmVuu5q2IvupFZq9VK7dq1vXLsiIgI/XL6CfWl/1Bf+g/1pf9QX/qPsvTl+UZk8+kEMBERERHxWQqzIiIiIuKzFGbLgd1u5+mnn8Zut3u7KVJG6kv/ob70H+pL/6G+9B/l2ZcX3QlgIiIiIuI/NDIrIiIiIj5LYVZEREREfJbCrIiIiIj4LIVZEREREfFZCrMX2Ntvv039+vUJDg6mXbt2rFixwttNkvNYvnw5N9xwAzVr1sRisfDVV18VeN0wDJ555hlq1qxJSEgI3bp1Y/Pmzd5prJzTpEmT6NChA+Hh4VSvXp3+/fuzffv2AuuoP33D1KlTad26tXsC9k6dOvHtt9+6X1c/+q5JkyZhsVgYN26ce5n60zc888wzWCyWArcaNWq4Xy+vflSYvYDmzp3LuHHjmDBhAuvXr6dLly706dOHhIQEbzdNziE9PZ02bdrw5ptvFvn6Sy+9xOTJk3nzzTdZs2YNNWrUoFevXqSmppZzS+V8li1bxv3338/q1auJj48nNzeX3r17k56e7l5H/ekbateuzYsvvsjatWtZu3Yt11xzDTfddJP7D6P60TetWbOG9957j9atWxdYrv70HS1atCAxMdF927Rpk/u1cutHQy6Yyy+/3Bg1alSBZU2bNjUee+wxL7VISgow5s+f737ucrmMGjVqGC+++KJ7WVZWlhEZGWm88847XmihlERSUpIBGMuWLTMMQ/3p66KioowPPvhA/eijUlNTjcaNGxvx8fHG1VdfbTz44IOGYej30pc8/fTTRps2bYp8rTz7USOzF0hOTg7r1q2jd+/eBZb37t2bVatWealVUla7d+/m0KFDBfrVbrdz9dVXq199wMmTJwGIjo4G1J++yul0MmfOHNLT0+nUqZP60Ufdf//99OvXj549exZYrv70LX/99Rc1a9akfv36DBo0iF27dgHl248BHt2buCUnJ+N0OomJiSmwPCYmhkOHDnmpVVJW+X1XVL/u3bvXG02SYjIMg/Hjx3PVVVfRsmVLQP3pazZt2kSnTp3IysqiUqVKzJ8/n+bNm7v/MKoffcecOXP47bffWLNmTaHX9HvpOzp27MiHH37IJZdcwuHDh3n++efp3LkzmzdvLtd+VJi9wCwWS4HnhmEUWia+R/3qe8aMGcPvv//OTz/9VOg19advaNKkCRs2bODEiRN88cUX3H333Sxbtsz9uvrRN+zbt48HH3yQRYsWERwcfNb11J8VX58+fdyPW7VqRadOnWjYsCGzZs3iiiuuAMqnH1VmcIFUrVoVm81WaBQ2KSmp0P9SxHfkn6WpfvUtY8eOZcGCBSxZsoTatWu7l6s/fUtQUBCNGjWiffv2TJo0iTZt2vCf//xH/ehj1q1bR1JSEu3atSMgIICAgACWLVvG66+/TkBAgLvP1J++JywsjFatWvHXX3+V6++lwuwFEhQURLt27YiPjy+wPD4+ns6dO3upVVJW9evXp0aNGgX6NScnh2XLlqlfKyDDMBgzZgxffvklixcvpn79+gVeV3/6NsMwyM7OVj/6mB49erBp0yY2bNjgvrVv354777yTDRs20KBBA/Wnj8rOzmbr1q3ExsaW7++lR08nkwLmzJljBAYGGtOmTTO2bNlijBs3zggLCzP27Nnj7abJOaSmphrr16831q9fbwDG5MmTjfXr1xt79+41DMMwXnzxRSMyMtL48ssvjU2bNhm33367ERsba6SkpHi55XKmv//970ZkZKSxdOlSIzEx0X3LyMhwr6P+9A2PP/64sXz5cmP37t3G77//bjzxxBOG1Wo1Fi1aZBiG+tHXnT6bgWGoP33FQw89ZCxdutTYtWuXsXr1auP66683wsPD3TmnvPpRYfYCe+utt4y4uDgjKCjIuOyyy9xTAknFtWTJEgModLv77rsNwzCnG3n66aeNGjVqGHa73ejatauxadMm7zZailRUPwLGjBkz3OuoP33D8OHD3f+WVqtWzejRo4c7yBqG+tHXnRlm1Z++YeDAgUZsbKwRGBho1KxZ07j55puNzZs3u18vr360GIZheHasV0RERESkfKhmVkRERER8lsKsiIiIiPgshVkRERER8VkKsyIiIiLisxRmRURERMRnKcyKiIiIiM9SmBURERERn6UwKyIiIiI+S2FWROQiZrFY+Oqrr7zdDBGRUlOYFRHxkqFDh2KxWArdrrvuOm83TUTEZwR4uwEiIhez6667jhkzZhRYZrfbvdQaERHfo5FZEREvstvt1KhRo8AtKioKMEsApk6dSp8+fQgJCaF+/frMmzevwPabNm3immuuISQkhCpVqnDvvfeSlpZWYJ3p06fTokUL7HY7sbGxjBkzpsDrycnJ/O1vfyM0NJTGjRuzYMGCC/umRUQ8SGFWRKQCe/LJJ7nlllvYuHEjd911F7fffjtbt24FICMjg+uuu46oqCjWrFnDvHnz+OGHHwqE1alTp3L//fdz7733smnTJhYsWECjRo0KHGPixIncdttt/P777/Tt25c777yTY8eOlev7FBEpLYthGIa3GyEicjEaOnQos2fPJjg4uMDyRx99lCeffBKLxcKoUaOYOnWq+7UrrriCyy67jLfffpv333+fRx99lH379hEWFgbAwoULueGGGzh48CAxMTHUqlWLYcOG8fzzzxfZBovFwj//+U+ee+45ANLT0wkPD2fhwoWq3RURn6CaWRERL+revXuBsAoQHR3tftypU6cCr3Xq1IkNGzYAsHXrVtq0aeMOsgBXXnklLpeL7du3Y7FYOHjwID169DhnG1q3bu1+HBYWRnh4OElJSaV9SyIi5UphVkTEi8LCwgp97X8+FosFAMMw3I+LWickJKRY+wsMDCy0rcvlKlGbRES8RTWzIiIV2OrVqws9b9q0KQDNmzdnw4YNpKenu19fuXIlVquVSy65hPDwcOrVq8ePP/5Yrm0WESlPGpkVEfGi7OxsDh06VGBZQEAAVatWBWDevHm0b9+eq666io8//phff/2VadOmAXDnnXfy9NNPc/fdd/PMM89w5MgRxo4dy+DBg4mJiQHgmWeeYdSoUVSvXp0+ffqQmprKypUrGTt2bPm+URGRC0RhVkTEi7777jtiY2MLLGvSpAnbtm0DzJkG5syZw+jRo6lRowYff/wxzZs3ByA0NJTvv/+eBx98kA4dOhAaGsott9zC5MmT3fu6++67ycrK4rXXXuMf//gHVatWZcCAAeX3BkVELjDNZiAiUkFZLBbmz59P//79vd0UEZEKSzWzIiIiIuKzFGZFRERExGepZlZEpIJSFZiIyPlpZFZEREREfJbCrIiIiIj4LIVZEREREfFZCrMiIiIi4rMUZkVERETEZynMioiIiIjPUpgVEREREZ+lMCsiIiIiPuv/AR6+BC26ld2BAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot 1: Epoch vs Accuracy (train vs validation)\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Epoch vs Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a1da4",
   "metadata": {},
   "source": [
    "## Metrics for Keras MLP on the test set\n",
    "\n",
    "- What: Compute accuracy, precision, recall, and F1-score on the held-out test set.\n",
    "- Why: Accuracy alone can hide per-class performance; macro-averaged precision/recall/F1 give a balanced view across classes.\n",
    "- Steps:\n",
    "  1. Predict class probabilities with `model.predict` and convert to labels via `argmax`.\n",
    "  2. Compute metrics with scikit-learn.\n",
    "  3. Inspect per-class `classification_report` and the confusion matrix to spot systematic errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras MLP Accuracy: 0.9880\n",
      "Precision (macro): 0.9883\n",
      "Recall (macro):    0.9879\n",
      "F1-score (macro):  0.9881\n",
      "\n",
      "Per-class report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       135\n",
      "           1       0.99      0.99      0.99      1476\n",
      "           2       0.99      0.99      0.99      1143\n",
      "           3       0.99      0.98      0.99       747\n",
      "           4       0.99      0.99      0.99      1197\n",
      "           5       1.00      1.00      1.00      1224\n",
      "           6       1.00      1.00      1.00       441\n",
      "           7       1.00      0.99      1.00       351\n",
      "           8       0.99      1.00      1.00       234\n",
      "           9       0.99      1.00      1.00       630\n",
      "          10       0.98      0.98      0.98       684\n",
      "          11       0.98      0.97      0.97       117\n",
      "          12       0.98      0.97      0.98       783\n",
      "          13       0.97      0.95      0.96       198\n",
      "          14       1.00      1.00      1.00       180\n",
      "          15       0.99      1.00      0.99       216\n",
      "          16       1.00      0.99      0.99       288\n",
      "          17       0.99      0.98      0.98       153\n",
      "          18       0.99      0.99      0.99       855\n",
      "          19       0.98      0.97      0.98       342\n",
      "          20       0.97      1.00      0.99       135\n",
      "          21       0.99      0.99      0.99       306\n",
      "          22       0.99      0.98      0.99       153\n",
      "          23       0.98      0.98      0.98       801\n",
      "          24       0.98      0.97      0.97       252\n",
      "          25       1.00      0.98      0.99       441\n",
      "          26       0.98      0.99      0.99       135\n",
      "          27       1.00      1.00      1.00       387\n",
      "          28       0.99      0.99      0.99       234\n",
      "          29       1.00      1.00      1.00       684\n",
      "          30       0.98      1.00      0.99       216\n",
      "          31       1.00      1.00      1.00       117\n",
      "          32       0.99      1.00      1.00      1179\n",
      "          33       1.00      1.00      1.00       171\n",
      "          34       0.98      0.99      0.98      1125\n",
      "          35       0.98      0.98      0.98       198\n",
      "          36       0.99      0.96      0.98       135\n",
      "          37       0.99      1.00      1.00       135\n",
      "          38       0.98      0.97      0.97      1053\n",
      "          39       0.99      1.00      0.99       234\n",
      "          40       0.99      0.97      0.98       819\n",
      "          41       0.97      0.98      0.98       801\n",
      "          42       1.00      0.99      0.99       837\n",
      "\n",
      "    accuracy                           0.99     21942\n",
      "   macro avg       0.99      0.99      0.99     21942\n",
      "weighted avg       0.99      0.99      0.99     21942\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 135    0    0 ...    0    0    0]\n",
      " [   0 1457    0 ...    1    0    0]\n",
      " [   0    0 1136 ...    0    0    0]\n",
      " ...\n",
      " [   1    1    0 ...  797    6    0]\n",
      " [   0    0    0 ...    2  786    2]\n",
      " [   0    0    4 ...    0    2  829]]\n"
     ]
    }
   ],
   "source": [
    "# Compute metrics for the Keras MLP on the test set\n",
    "# - y_prob: class probabilities from softmax for each sample\n",
    "# - argmax across classes to convert probabilities into predicted labels\n",
    "# - macro-averaged precision/recall/F1 treat all classes equally\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
    "\n",
    "y_prob = model.predict(X_test_np, verbose=0)\n",
    "y_pred_keras = y_prob.argmax(axis=1)\n",
    "\n",
    "keras_acc = accuracy_score(y_test_np, y_pred_keras)\n",
    "print(f\"Keras MLP Accuracy: {keras_acc:.4f}\")\n",
    "\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "    y_test_np, y_pred_keras, average='macro', zero_division=0\n",
    ")\n",
    "print(f\"Precision (macro): {prec:.4f}\")\n",
    "print(f\"Recall (macro):    {rec:.4f}\")\n",
    "print(f\"F1-score (macro):  {f1:.4f}\")\n",
    "\n",
    "print(\"\\nPer-class report:\")\n",
    "print(classification_report(y_test_np, y_pred_keras))\n",
    "\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(confusion_matrix(y_test_np, y_pred_keras))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
